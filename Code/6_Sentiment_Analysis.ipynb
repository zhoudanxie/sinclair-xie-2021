{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import time\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           822737 non-null  object\n",
      " 1   RegSentsExpand               822737 non-null  object\n",
      " 2   NounChunksMatch              822737 non-null  int64 \n",
      " 3   NounChunkMatchWords          822737 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  822737 non-null  object\n",
      " 5   NounChunkMatchFiltered       822737 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 37.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import regulatory sections with matched noun chunks\n",
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 502909 entries, 0 to 502908\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           502909 non-null  object\n",
      " 1   RegSentsExpand               502909 non-null  object\n",
      " 2   NounChunksMatch              502909 non-null  int64 \n",
      " 3   NounChunkMatchWords          502909 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  502909 non-null  object\n",
      " 5   NounChunkMatchFiltered       502909 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 23.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Refine to reg relevant articles\n",
    "df=df_regSentsExpand[df_regSentsExpand['NounChunkMatchFiltered']>0].reset_index(drop=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Match uncertainty words using LM dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negation words\n",
    "negate = [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\", \"ain't\", \"aren't\", \"can't\",\n",
    "          \"couldn't\", \"daren't\", \"didn't\", \"doesn't\", \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\",\n",
    "          \"neither\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\", \"neednt\", \"needn't\",\n",
    "          \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\", \"oughtnt\", \"shant\", \"shouldnt\", \"wasnt\",\n",
    "          \"werent\", \"oughtn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"without\", \"wont\", \"wouldnt\", \"won't\",\n",
    "          \"wouldn't\", \"rarely\", \"seldom\", \"despite\", \"no\", \"nobody\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to negate\n",
    "def negated(word):\n",
    "    # Determine if preceding word is a negation word\n",
    "    if word.lower() in negate:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize\n",
    "def tokenizer(text):\n",
    "    doc=nlp(text)\n",
    "    tokens=[token.text.lower() for token in doc if not token.is_punct | token.is_space]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lemmatize\n",
    "def lemmatizer(text):\n",
    "    doc=nlp(text)\n",
    "    lemmas=[token.lemma_ for token in doc if not token.is_punct | token.is_space]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2355 entries, 0 to 2354\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Negative     2355 non-null   object\n",
      " 1   Positive     354 non-null    object\n",
      " 2   Uncertainty  297 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 55.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# LM dictionary\n",
    "LMlist=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LoughranMcDonald_SentimentList.csv')\n",
    "print(LMlist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LM uncertainty dictionary\n",
    "LMuncertain=LMlist[LMlist['Uncertainty'].notnull()]['Uncertainty'].tolist()\n",
    "uncertaindict={'Uncertainty': [w.lower() for w in LMuncertain]}\n",
    "#print(uncertaindict, len(LMuncertain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize LM uncertainty dictionary\n",
    "uncertainset=set()\n",
    "for w in uncertaindict['Uncertainty']:\n",
    "    v=''.join(lemmatizer(w))\n",
    "    uncertainset.add(v)\n",
    "uncertainlist_lemmatized=list(uncertainset)\n",
    "print(len(uncertainlist_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hide', 'nonassessable', 'alteration', 'clarification', 'imprecision', 'imprecise', 'vaguely', 'differ', 'indeterminate', 'unforseen', 'cautious', 'apparently', 'approximated', 'recalculated', 'arbitrary', 'indefinite', 'confusion', 'crossroad', 'hinge', 'possibility']\n"
     ]
    }
   ],
   "source": [
    "print(uncertainlist_lemmatized[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count uncertainty terms\n",
    "def uncertainty_count(keywords_list, article):\n",
    "\n",
    "    uncertain_count = 0\n",
    "    uncertain_words = []\n",
    " \n",
    "    input_words=lemmatizer(article)\n",
    "    word_count = len(input_words)\n",
    "    \n",
    "    for i in range(0, word_count):\n",
    "        if input_words[i] in keywords_list:\n",
    "            uncertain_count += 1\n",
    "            uncertain_words.append(input_words[i])\n",
    "    \n",
    "    results = [uncertain_count, uncertain_words]\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502909\n"
     ]
    }
   ],
   "source": [
    "# Run LM uncertainty through all expanded reg sentences\n",
    "UncertaintyCount=[]\n",
    "UncertaintyWords=[]\n",
    "for text in df['RegSentsExpand']:\n",
    "    results=uncertainty_count(uncertainlist_lemmatized, text)\n",
    "    UncertaintyCount.append(results[0])\n",
    "    UncertaintyWords.append(results[1])\n",
    "print(len(UncertaintyCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 502909 entries, 0 to 502908\n",
      "Data columns (total 8 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           502909 non-null  object\n",
      " 1   RegSentsExpand               502909 non-null  object\n",
      " 2   NounChunksMatch              502909 non-null  int64 \n",
      " 3   NounChunkMatchWords          502909 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  502909 non-null  object\n",
      " 5   NounChunkMatchFiltered       502909 non-null  int64 \n",
      " 6   UncertaintyCount             502909 non-null  int64 \n",
      " 7   UncertaintyWords             502909 non-null  object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 30.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df['UncertaintyCount']=UncertaintyCount\n",
    "df['UncertaintyWords']=UncertaintyWords\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273029\n"
     ]
    }
   ],
   "source": [
    "print(df[df['UncertaintyCount']!=0]['ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  UncertaintyCount   UncertaintyWords\n",
      "0  294326637                 0                 []\n",
      "1  294308147                 0                 []\n",
      "2  294323196                 1            [could]\n",
      "3  294262284                 2  [possible, could]\n",
      "4  294234319                 0                 []\n",
      "5  294323101                 1         [exposure]\n",
      "6  294205735                 1           [revise]\n",
      "7  294261564                 0                 []\n",
      "8  294337453                 1            [pende]\n",
      "9  294281403                 2     [appear, seem]\n"
     ]
    }
   ],
   "source": [
    "print(df[['ID','UncertaintyCount','UncertaintyWords']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','UncertaintyCount','UncertaintyWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LMuncertainty.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Match sentiment words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 LM dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count sentiment terms\n",
    "def sentiment_count(dict, article):\n",
    "    \"\"\"\n",
    "    Count positive and negative words with negation check. Account for simple negation only for positive words.\n",
    "    Simple negation is taken to be observations of one of negate words occurring within three words\n",
    "    preceding a positive words.\n",
    "    \"\"\"\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    " \n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    " \n",
    "    input_words=lemmatizer(article)\n",
    " \n",
    "    word_count = len(input_words)\n",
    " \n",
    "    for i in range(0, word_count):\n",
    "        if input_words[i] in dict['Negative']:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                neg_count += 1\n",
    "                neg_words.append(input_words[i])\n",
    "            \n",
    "        if input_words[i] in dict['Positive']:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                pos_count += 1\n",
    "                pos_words.append(input_words[i])\n",
    "    '''\n",
    "    print('The results with negation check:', end='\\n\\n')\n",
    "    print('The # of positive words:', pos_count)\n",
    "    print('The # of negative words:', neg_count)\n",
    "    print('The list of found positive words:', pos_words)\n",
    "    print('The list of found negative words:', neg_words)\n",
    "    print('\\n', end='')\n",
    "    '''\n",
    "    \n",
    "    results = [word_count, pos_count, neg_count, pos_words, neg_words]\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355 354\n",
      "['ABANDON', 'ABANDONED', 'ABANDONING', 'ABANDONMENT', 'ABANDONMENTS', 'ABANDONS', 'ABDICATED', 'ABDICATES', 'ABDICATING', 'ABDICATION', 'ABDICATIONS', 'ABERRANT', 'ABERRATION', 'ABERRATIONAL', 'ABERRATIONS', 'ABETTING', 'ABNORMAL', 'ABNORMALITIES', 'ABNORMALITY', 'ABNORMALLY'] ['ABLE', 'ABUNDANCE', 'ABUNDANT', 'ACCLAIMED', 'ACCOMPLISH', 'ACCOMPLISHED', 'ACCOMPLISHES', 'ACCOMPLISHING', 'ACCOMPLISHMENT', 'ACCOMPLISHMENTS', 'ACHIEVE', 'ACHIEVED', 'ACHIEVEMENT', 'ACHIEVEMENTS', 'ACHIEVES', 'ACHIEVING', 'ADEQUATELY', 'ADVANCEMENT', 'ADVANCEMENTS', 'ADVANCES']\n"
     ]
    }
   ],
   "source": [
    "# LM sentiment dictionary\n",
    "LMposWords=LMlist[LMlist['Positive'].notnull()]['Positive'].tolist()\n",
    "LMnegWords=LMlist[LMlist['Negative'].notnull()]['Negative'].tolist()\n",
    "print(len(LMnegWords),len(LMposWords))\n",
    "print(LMnegWords[0:20],LMposWords[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize LM sentiment dictionary\n",
    "LMnegset=set()\n",
    "for w in LMnegWords:\n",
    "    v=''.join(lemmatizer(w.lower()))\n",
    "    LMnegset.add(v)\n",
    "print(len(LMnegset))\n",
    "\n",
    "LMposset=set()\n",
    "for w in LMposWords:\n",
    "    v=''.join(lemmatizer(w.lower()))\n",
    "    LMposset.add(v)\n",
    "print(len(LMposset))\n",
    "\n",
    "LMdict={'Negative': list(LMnegset), 'Positive': list(LMposset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charitable', 'dream', 'satisfie', 'bolstering', 'ideal', 'excited', 'smoothly', 'creative', 'bolster', 'boom', 'revolutionizes', 'complimenting', 'able', 'favorable', 'preeminence', 'diligently', 'easy', 'honorable', 'accomplishing', 'exclusively']\n",
      "['incarcerate', 'obsolescence', 'incapacitate', 'miss', 'renounced', 'uneconomic', 'unfunded', 'unacceptably', 'deceitful', 'litigant', 'retaliated', 'discourage', 'stoppage', 'unfavorability', 'alienation', 'repudiation', 'expose', 'unsaleable', 'nonproductive', 'shortfall']\n"
     ]
    }
   ],
   "source": [
    "print(LMdict['Positive'][0:20])\n",
    "print(LMdict['Negative'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LM sentiment through all expanded reg sentences\n",
    "LMpositiveCount=[]\n",
    "LMnegativeCount=[]\n",
    "LMpositiveWords=[]\n",
    "LMnegativeWords=[]\n",
    "for text in df['RegSentsExpand']:\n",
    "    results=sentiment_count(LMdict, text)\n",
    "    LMpositiveCount.append(results[1])\n",
    "    LMnegativeCount.append(results[2])\n",
    "    LMpositiveWords.append(results[3])\n",
    "    LMnegativeWords.append(results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LMposCount']=LMpositiveCount\n",
    "df['LMnegCount']=LMnegativeCount\n",
    "df['LMposWords']=LMpositiveWords\n",
    "df['LMnegWords']=LMnegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','LMposCount','LMnegCount','LMposWords','LMnegWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LMsentiments.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 GI dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harvard GI sentiment dictionary\n",
    "with open(\"/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/GIposWords.txt\", \"rb\") as fp:   # Unpickling\n",
    "    GIposWords = pickle.load(fp)\n",
    "with open(\"/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/GInegWords.txt\", \"rb\") as fp:   # Unpickling\n",
    "    GInegWords = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637 ['ABIDE', 'ABILITY', 'ABLE', 'ABOUND', 'ABSOLVE', 'ABSORBENT', 'ABSORPTION', 'ABUNDANCE', 'ABUNDANT', 'ACCEDE', 'ACCENTUATE', 'ACCEPT', 'ACCEPTABLE', 'ACCEPTANCE', 'ACCESSIBLE', 'ACCESSION', 'ACCLAIM', 'ACCLAMATION', 'ACCOLADE', 'ACCOMMODATE']\n",
      "2005 ['ABANDON', 'ABANDONMENT', 'ABATE', 'ABDICATE', 'ABHOR', 'ABJECT', 'ABNORMAL', 'ABOLISH', 'ABOMINABLE', 'ABRASIVE', 'ABRUPT', 'ABSCOND', 'ABSENCE', 'ABSENT', 'ABSENT-MINDED', 'ABSENTEE', 'ABSURD', 'ABSURDITY', 'ABUSE', 'ABYSS']\n"
     ]
    }
   ],
   "source": [
    "print(len(GIposWords),GIposWords[0:20])\n",
    "print(len(GInegWords),GInegWords[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lemmatize GI dictionary\n",
    "# GInegset=set()\n",
    "# for w in GInegWords:\n",
    "#     v=''.join(lemmatizer(w.lower()))\n",
    "#     GInegset.add(v)\n",
    "# GInegset.remove('-PRON-')\n",
    "# print(len(GInegset))\n",
    "\n",
    "# GIposset=set()\n",
    "# for w in GIposWords:\n",
    "#     v=''.join(lemmatizer(w.lower()))\n",
    "#     GIposset.add(v)\n",
    "# print(len(GIposset))\n",
    "\n",
    "# GIdict={'Negative': list(GInegset), 'Positive': list(GIposset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: ['abide', 'ability', 'able', 'abound', 'absolve', 'absorbent', 'absorption', 'abundance', 'abundant', 'accede', 'accentuate', 'accept', 'acceptable', 'acceptance', 'accessible', 'accession', 'acclaim', 'acclamation', 'accolade', 'accommodate']\n",
      "Negative: ['abandon', 'abandonment', 'abate', 'abdicate', 'abhor', 'abject', 'abnormal', 'abolish', 'abominable', 'abrasive', 'abrupt', 'abscond', 'absence', 'absent', 'absent-minded', 'absentee', 'absurd', 'absurdity', 'abuse', 'abyss']\n"
     ]
    }
   ],
   "source": [
    "# Non-lemmetized version of GI dictionary\n",
    "GIdict2={'Negative': [w.lower() for w in GInegWords], 'Positive': [w.lower() for w in GIposWords]}\n",
    "print('Positive:',GIdict2['Positive'][0:20])\n",
    "print('Negative:',GIdict2['Negative'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GI sentiment through all expanded reg sentences using non-lemmatized GI dictionary (performs better than lemmatized GI)\n",
    "totalWordCount=[]\n",
    "GIpositiveCount=[]\n",
    "GInegativeCount=[]\n",
    "GIpositiveWords=[]\n",
    "GInegativeWords=[]\n",
    "for text in df['RegSentsExpand']:\n",
    "    results=sentiment_count(GIdict2, text)\n",
    "    totalWordCount.append(results[0])\n",
    "    GIpositiveCount.append(results[1])\n",
    "    GInegativeCount.append(results[2])\n",
    "    GIpositiveWords.append(results[3])\n",
    "    GInegativeWords.append(results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalWordCount']=totalWordCount\n",
    "df['GIposCount']=GIpositiveCount\n",
    "df['GInegCount']=GInegativeCount\n",
    "df['GIposWords']=GIpositiveWords\n",
    "df['GInegWords']=GInegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','TotalWordCount','GIposCount','GInegCount','GIposWords','GInegWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/GIsentiments.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 LSD dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicoder Sentiment Dictionary (LSD)\n",
    "LSDlist=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LSDsentimentWords_wStar.csv')\n",
    "print(LSDlist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSDneg=LSDlist[LSDlist['LSDnegative'].notnull()]['LSDnegative'].tolist()\n",
    "LSDpos=LSDlist[LSDlist['LSDpositive'].notnull()]['LSDpositive'].tolist()\n",
    "LSDdict={'Negative': [w.lower() for w in LSDneg], 'Positive': [w.lower() for w in LSDpos]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate terms with & without stars in LSD dictionary\n",
    "pos_star=[]\n",
    "pos_nostar=[]\n",
    "for m in LSDdict['Positive']:\n",
    "    if \"*\" in m:\n",
    "        m=m.replace('*','')\n",
    "        pos_star.append(m)\n",
    "    else:\n",
    "        pos_nostar.append(m)\n",
    "print(len(pos_star), len(pos_nostar))\n",
    "\n",
    "neg_star=[]\n",
    "neg_nostar=[]\n",
    "for m in LSDdict['Negative']:\n",
    "    if \"*\" in m:\n",
    "        m=m.replace('*','')\n",
    "        neg_star.append(m)\n",
    "    else:\n",
    "        neg_nostar.append(m)\n",
    "print(len(neg_star), len(neg_nostar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile re patterns for terms with & without stars\n",
    "pattern_pos_nostar=re.compile(r'\\b(?:%s)\\b' % '|'.join(pos_nostar))\n",
    "pattern_pos_star=re.compile(r'\\b(?:%s)[a-zA-Z]*\\b' % '|'.join(pos_star))\n",
    "pattern_neg_nostar=re.compile(r'\\b(?:%s)\\b' % '|'.join(neg_nostar))\n",
    "pattern_neg_star=re.compile(r'\\b(?:%s)[a-zA-Z]*\\b' % '|'.join(neg_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count LSD sentiment terms\n",
    "def LSDsentiment_count(dict, article):\n",
    "    \"\"\"\n",
    "    Count positive and negative words with negation check. Account for simple negation only for positive words.\n",
    "    Simple negation is taken to be observations of one of negate words occurring within three words\n",
    "    preceding a positive words.\n",
    "    \"\"\"\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    " \n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    " \n",
    "    input_words=tokenizer(article)    # No lemmatizing since LSD dictionary includes variations\n",
    " \n",
    "    word_count = len(input_words)\n",
    " \n",
    "    for i in range(0, word_count):\n",
    "        find_neg=pattern_neg_nostar.findall(input_words[i])+pattern_neg_star.findall(input_words[i])\n",
    "        if len(find_neg)>0:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                neg_count += 1\n",
    "                neg_words.append(input_words[i])\n",
    "        \n",
    "        find_pos=pattern_pos_nostar.findall(input_words[i])+pattern_pos_star.findall(input_words[i])\n",
    "        if len(find_pos)>0:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                pos_count += 1\n",
    "                pos_words.append(input_words[i])\n",
    "    '''\n",
    "    print('The results with negation check:', end='\\n\\n')\n",
    "    print('The # of positive words:', pos_count)\n",
    "    print('The # of negative words:', neg_count)\n",
    "    print('The list of found positive words:', pos_words)\n",
    "    print('The list of found negative words:', neg_words)\n",
    "    print('\\n', end='')\n",
    "    '''\n",
    "    \n",
    "    results = [word_count, pos_count, neg_count, pos_words, neg_words]\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LSD sentiment through all expanded reg sentences\n",
    "start_time = time.time()\n",
    "\n",
    "LSDpositiveCount=[]\n",
    "LSDnegativeCount=[]\n",
    "LSDpositiveWords=[]\n",
    "LSDnegativeWords=[]\n",
    "failed=[]\n",
    "for i in range(0, len(df['RegSentsExpand'])):\n",
    "    try:\n",
    "        results=LSDsentiment_count(LSDdict, df['RegSentsExpand'][i])\n",
    "    except:\n",
    "        results=[None, None, None, None, None]\n",
    "        failed.append(i)        \n",
    "        \n",
    "    LSDpositiveCount.append(results[1])\n",
    "    LSDnegativeCount.append(results[2])\n",
    "    LSDpositiveWords.append(results[3])\n",
    "    LSDnegativeWords.append(results[4])\n",
    "print(len(failed))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(failed))\n",
    "print(len(LSDpositiveWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LSDposCount']=LSDpositiveCount\n",
    "df['LSDnegCount']=LSDnegativeCount\n",
    "df['LSDposWords']=LSDpositiveWords\n",
    "df['LSDnegWords']=LSDnegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    print(df['RegSentsExpand'][i],df['LSDposWords'][i],df['LSDnegWords'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','LSDposCount','LSDnegCount','LSDposWords','LSDnegWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LSDsentiments.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
