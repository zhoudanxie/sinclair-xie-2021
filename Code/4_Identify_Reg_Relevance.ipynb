{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/nltk_data',\n",
       " '/home/ec2-user/SageMaker/.conda/envs/my_py/nltk_data',\n",
       " '/home/ec2-user/SageMaker/.conda/envs/my_py/share/nltk_data',\n",
       " '/home/ec2-user/SageMaker/.conda/envs/my_py/lib/nltk_data',\n",
       " '/usr/share/nltk_data',\n",
       " '/usr/local/share/nltk_data',\n",
       " '/usr/lib/nltk_data',\n",
       " '/usr/local/lib/nltk_data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.data.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text preprocessor (lemmatizer)\n",
    "def my_preprocessor(text):\n",
    "    doc=nlp(text.lower())\n",
    "    lemmas=[token.lemma_ for token in doc if not token.is_punct | token.is_space]\n",
    "    texts_out=\" \".join(lemmas)\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   ID              822737 non-null  object\n",
      " 1   RegSentsExpand  822737 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import expanded reg sentences\n",
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/allRegSentsExpand.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reg sentences to list\n",
    "regSentsExpand=df_regSentsExpand['RegSentsExpand'].tolist()\n",
    "print(len(regSentsExpand), regSentsExpand[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "print(regSentsExpand[4031])\n",
    "print(my_preprocessor(regSentsExpand[4031]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all expanded reg sentences\n",
    "regSentsExpand_lemmatized=[my_preprocessor(sent) for sent in regSentsExpand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "print(len(regSentsExpand_lemmatized), regSentsExpand_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regSentsExpand[1],regSentsExpand_lemmatized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save preprocessed expanded reg sentences\n",
    "# with open('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/regSentsExpand_lemmatized', 'wb') as fp:\n",
    "#     pickle.dump(regSentsExpand_lemmatized, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Match Noun Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed expanded reg sentences\n",
    "with open ('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/regSentsExpand_lemmatized', 'rb') as fp:\n",
    "    regSentsExpand_lemmatized = pickle.load(fp)\n",
    "print(len(regSentsExpand_lemmatized), regSentsExpand_lemmatized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37735 ['$ 3 immigration user fee', '-PRON- 2014 2018 greenhouse gas emission standard and fuel efficiency standard', '-PRON- acetate', '-PRON- affiliate', '-PRON- approach', '-PRON- associated privacy act exemption', '-PRON- be portable tank', '-PRON- beneficiary', '-PRON- catcher vessel', '-PRON- character', '-PRON- chemical mixture', '-PRON- child act', '-PRON- community access', '-PRON- computer assist execution system linkage', '-PRON- conduct', '-PRON- correspondent bank', '-PRON- customer', '-PRON- customer requirement', '-PRON- dependent', '-PRON- employee']\n"
     ]
    }
   ],
   "source": [
    "# Use all unique noun chunks in rule titles\n",
    "with open ('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/ruleTitleUniqueNounChunks', 'rb') as fp:\n",
    "    nounchunks = pickle.load(fp)\n",
    "print(len(nounchunks),nounchunks[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile a new re pattern with all noun chunks\n",
    "pattern=re.compile(r\"\\b\"+r\"\\b|\\b\".join(map(re.escape, nounchunks))+r\"\\b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match noun chunks in all expanded reg sentences\n",
    "start_time = time.time()\n",
    "\n",
    "nounchunk_match=[]\n",
    "nounchunk_match_words=[]\n",
    "for sent in regSentsExpand_lemmatized:\n",
    "    match_words=[]\n",
    "    match=0\n",
    "    find=pattern.findall(sent)\n",
    "    if len(find)>0:\n",
    "        match_words=find\n",
    "        match=len(find)\n",
    "    nounchunk_match.append(match)\n",
    "    nounchunk_match_words.append(match_words)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of matched noun chunks\n",
    "print(len(nounchunk_match), len(nounchunk_match_words))\n",
    "print(nounchunk_match_words[-1], nounchunk_match[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_regSentsExpand.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_regSentsExpand[df_regSentsExpand['NounChunksMatch']>0].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results: matched noun chunks in expanded reg sentences\n",
    "df_regSentsExpand['NounChunksMatch']=nounchunk_match\n",
    "df_regSentsExpand['NounChunkMatchWords']=nounchunk_match_words\n",
    "df_regSentsExpand.to_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Noun Chunk Occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           822737 non-null  object\n",
      " 1   RegSentsExpand               822737 non-null  object\n",
      " 2   NounChunksMatch              822737 non-null  int64 \n",
      " 3   NounChunkMatchWords          822737 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  822737 non-null  object\n",
      " 5   NounChunkMatchFiltered       822737 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 37.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   ID      788516 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 6.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated articles\n",
    "IDs_nodup=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/IDs_no_duplicates.csv')\n",
    "print(IDs_nodup.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           788516 non-null  int64 \n",
      " 1   RegSentsExpand               788516 non-null  object\n",
      " 2   NounChunksMatch              788516 non-null  int64 \n",
      " 3   NounChunkMatchWords          788516 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  788516 non-null  object\n",
      " 5   NounChunkMatchFiltered       788516 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 36.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_regSentsExpand['ID']=df_regSentsExpand['ID'].astype('int64')\n",
    "df_regSentsExpand=IDs_nodup.merge(df_regSentsExpand,on='ID',how='left').reset_index(drop=True)\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All unique macthed noun chunks and occurences from expanded reg sentences\n",
    "allMatchWords=[]\n",
    "for list in df_regSentsExpand['NounChunkMatchWords']:\n",
    "    allMatchWords=allMatchWords+list\n",
    "print(len(allMatchWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(allMatchWords[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allMatchWordsCount=Counter(allMatchWords)\n",
    "print(allMatchWordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11358 entries, 0 to 11357\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Noun Chunks  11358 non-null  object\n",
      " 1   Occurences   11358 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 177.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_MatchWords = pd.DataFrame(allMatchWordsCount.items(),columns = ['Noun Chunks','Occurences'])\n",
    "print(df_MatchWords.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Noun Chunks  Occurences\n",
      "0            new york       65836\n",
      "1      new regulation       29880\n",
      "2       united states       28376\n",
      "3  federal regulation       22168\n",
      "4         los angeles       19997\n"
     ]
    }
   ],
   "source": [
    "df_MatchWords=df_MatchWords.sort_values('Occurences',ascending=False).reset_index(drop=True)\n",
    "print(df_MatchWords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export noun chunk occurences\n",
    "df_MatchWords.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunkOccurences3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove General Terms after Human Auditing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 713 entries, 0 to 712\n",
      "Data columns (total 1 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Noun Chunks  713 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 5.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove general terms from matched noun chunks in expanded reg sentences\n",
    "df_MatchWordsRemove=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunkOccurences3_Remove.csv')\n",
    "print(df_MatchWordsRemove.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 capital', '1 filing', '10 gallon', '10 guideline', '10 specie', '10 usc', '10,000 year', '100 foot', '100 revision', '103 regulation', '11 plant', '11 usc', '12 cfr', '12 specie', '12,500 pound', '120 volt', '13 case', '13 plant', '14,000 pound', '15 cfr']\n"
     ]
    }
   ],
   "source": [
    "# Noun chunks to be removed (\"general terms\")\n",
    "matchwords_remove=df_MatchWordsRemove['Noun Chunks'].tolist()\n",
    "print(matchwords_remove[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg sections with all matched noun chunks\n",
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           822737 non-null  object\n",
      " 1   RegSentsExpand               822737 non-null  object\n",
      " 2   NounChunksMatch              822737 non-null  int64 \n",
      " 3   NounChunkMatchWords          822737 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  822737 non-null  object\n",
      " 5   NounChunkMatchFiltered       822737 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 37.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove general terms from all matched noun chunks\n",
    "df_regSentsExpand['NounChunkMatchWordsFiltered']=np.nan\n",
    "df_regSentsExpand['NounChunkMatchFiltered']=0\n",
    "for i in range(0,len(df_regSentsExpand['NounChunkMatchWords'])):\n",
    "    df_regSentsExpand['NounChunkMatchWordsFiltered'][i]=[w for w in df_regSentsExpand['NounChunkMatchWords'][i] \n",
    "                                                         if w not in matchwords_remove]\n",
    "    df_regSentsExpand['NounChunkMatchFiltered'][i]=len(df_regSentsExpand['NounChunkMatchWordsFiltered'][i])\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 502740 entries, 0 to 822736\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           502740 non-null  object\n",
      " 1   RegSentsExpand               502740 non-null  object\n",
      " 2   NounChunksMatch              502740 non-null  int64 \n",
      " 3   NounChunkMatchWords          502740 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  502740 non-null  object\n",
      " 5   NounChunkMatchFiltered       502740 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 26.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_regSentsExpand[df_regSentsExpand['NounChunkMatchFiltered']>0].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>RegSentsExpand</th>\n",
       "      <th>NounChunksMatch</th>\n",
       "      <th>NounChunkMatchWords</th>\n",
       "      <th>NounChunkMatchWordsFiltered</th>\n",
       "      <th>NounChunkMatchFiltered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294326637</td>\n",
       "      <td>\"Deregulation of natural gas will lower your h...</td>\n",
       "      <td>1</td>\n",
       "      <td>[natural gas]</td>\n",
       "      <td>[natural gas]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>294308147</td>\n",
       "      <td>Because rates can be adjusted only after a pri...</td>\n",
       "      <td>3</td>\n",
       "      <td>[price change, price change, federal rule]</td>\n",
       "      <td>[price change, price change, federal rule]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>294323196</td>\n",
       "      <td>A federal appeals court yesterday upheld the N...</td>\n",
       "      <td>2</td>\n",
       "      <td>[nuclear regulatory commission, nuclear power ...</td>\n",
       "      <td>[nuclear regulatory commission, nuclear power ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>294311708</td>\n",
       "      <td>A man less secure in his prospects might have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>294262284</td>\n",
       "      <td>Legislation which would reduce employers' unem...</td>\n",
       "      <td>4</td>\n",
       "      <td>[unemployment compensation, tax liability, cre...</td>\n",
       "      <td>[unemployment compensation, tax liability, cre...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>294234319</td>\n",
       "      <td>US/WORLD NEWS BRIEFS     The Nuclear Regulator...</td>\n",
       "      <td>2</td>\n",
       "      <td>[nuclear regulatory commission, low power]</td>\n",
       "      <td>[nuclear regulatory commission]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>294323101</td>\n",
       "      <td>The plant closed Dec. 10, 1983 for its regular...</td>\n",
       "      <td>5</td>\n",
       "      <td>[nuclear regulatory commission, nuclear regula...</td>\n",
       "      <td>[nuclear regulatory commission, nuclear regula...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>294205735</td>\n",
       "      <td>Meanwhile, the Federal Aviation Administration...</td>\n",
       "      <td>1</td>\n",
       "      <td>[safety regulation]</td>\n",
       "      <td>[safety regulation]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>294222941</td>\n",
       "      <td>As more and more children recover, fewer and f...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>294261564</td>\n",
       "      <td>They are Sens. William R. Keating (D-Sharon), ...</td>\n",
       "      <td>3</td>\n",
       "      <td>[public safety, state administration, governme...</td>\n",
       "      <td>[public safety, state administration, governme...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                     RegSentsExpand  \\\n",
       "0  294326637  \"Deregulation of natural gas will lower your h...   \n",
       "1  294308147  Because rates can be adjusted only after a pri...   \n",
       "2  294323196  A federal appeals court yesterday upheld the N...   \n",
       "3  294311708  A man less secure in his prospects might have ...   \n",
       "4  294262284  Legislation which would reduce employers' unem...   \n",
       "5  294234319  US/WORLD NEWS BRIEFS     The Nuclear Regulator...   \n",
       "6  294323101  The plant closed Dec. 10, 1983 for its regular...   \n",
       "7  294205735  Meanwhile, the Federal Aviation Administration...   \n",
       "8  294222941  As more and more children recover, fewer and f...   \n",
       "9  294261564  They are Sens. William R. Keating (D-Sharon), ...   \n",
       "\n",
       "   NounChunksMatch                                NounChunkMatchWords  \\\n",
       "0                1                                      [natural gas]   \n",
       "1                3         [price change, price change, federal rule]   \n",
       "2                2  [nuclear regulatory commission, nuclear power ...   \n",
       "3                0                                                 []   \n",
       "4                4  [unemployment compensation, tax liability, cre...   \n",
       "5                2         [nuclear regulatory commission, low power]   \n",
       "6                5  [nuclear regulatory commission, nuclear regula...   \n",
       "7                1                                [safety regulation]   \n",
       "8                0                                                 []   \n",
       "9                3  [public safety, state administration, governme...   \n",
       "\n",
       "                         NounChunkMatchWordsFiltered  NounChunkMatchFiltered  \n",
       "0                                      [natural gas]                       1  \n",
       "1         [price change, price change, federal rule]                       3  \n",
       "2  [nuclear regulatory commission, nuclear power ...                       2  \n",
       "3                                                 []                       0  \n",
       "4  [unemployment compensation, tax liability, cre...                       4  \n",
       "5                    [nuclear regulatory commission]                       1  \n",
       "6  [nuclear regulatory commission, nuclear regula...                       5  \n",
       "7                                [safety regulation]                       1  \n",
       "8                                                 []                       0  \n",
       "9  [public safety, state administration, governme...                       3  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_regSentsExpand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural gas']\n",
      "['natural gas'] \n",
      "\n",
      "['price change', 'price change', 'federal rule']\n",
      "['price change', 'price change', 'federal rule'] \n",
      "\n",
      "['nuclear regulatory commission', 'nuclear power plant']\n",
      "['nuclear regulatory commission', 'nuclear power plant'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['unemployment compensation', 'tax liability', 'credit card', 'interest rate']\n",
      "['unemployment compensation', 'tax liability', 'credit card', 'interest rate'] \n",
      "\n",
      "['nuclear regulatory commission', 'low power']\n",
      "['nuclear regulatory commission'] \n",
      "\n",
      "['nuclear regulatory commission', 'nuclear regulatory commission', 'radiation protection', 'radiation exposure', 'construction worker']\n",
      "['nuclear regulatory commission', 'nuclear regulatory commission', 'radiation protection', 'radiation exposure', 'construction worker'] \n",
      "\n",
      "['safety regulation']\n",
      "['safety regulation'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['public safety', 'state administration', 'government regulation']\n",
      "['public safety', 'state administration', 'government regulation'] \n",
      "\n",
      "['attorney general']\n",
      "['attorney general'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['propose rule']\n",
      "['propose rule'] \n",
      "\n",
      "['tender offer']\n",
      "['tender offer'] \n",
      "\n",
      "['government regulation', 'organizational structure']\n",
      "['government regulation', 'organizational structure'] \n",
      "\n",
      "['travel agent', 'american society', 'travel agent', 'travel agent', 'air traveler', 'regulation govern', 'smoking restriction', 'air traffic', 'travel agent', 'military installation', 'travel agent', 'other person', 'government agency', 'consumer protection', 'international carrier', 'travel agent', 'travel agency', 'air travel']\n",
      "['travel agent', 'travel agent', 'travel agent', 'air traveler', 'smoking restriction', 'air traffic', 'travel agent', 'military installation', 'travel agent', 'government agency', 'consumer protection', 'international carrier', 'travel agent', 'travel agency', 'air travel'] \n",
      "\n",
      "['federal regulation', 'student loan', 'cross appeal']\n",
      "['federal regulation', 'student loan', 'cross appeal'] \n",
      "\n",
      "['second half']\n",
      "[] \n",
      "\n",
      "['new england', 'rhode island']\n",
      "[] \n",
      "\n",
      "['government regulation']\n",
      "['government regulation'] \n",
      "\n",
      "['new york', 'environmental quality', 'new standard', 'wetland regulation', 'five acre', 'new standard', 'agency regulation', 'environmental policy']\n",
      "['environmental quality', 'new standard', 'wetland regulation', 'new standard', 'agency regulation', 'environmental policy'] \n",
      "\n",
      "['new drug']\n",
      "['new drug'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['state regulation', 'health care', 'all kind']\n",
      "['state regulation', 'health care'] \n",
      "\n",
      "['oral argument']\n",
      "['oral argument'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['poison ivy', 'public health']\n",
      "['poison ivy', 'public health'] \n",
      "\n",
      "['federal deposit', 'commercial bank']\n",
      "['federal deposit', 'commercial bank'] \n",
      "\n",
      "['federal reserve', 'executive officer']\n",
      "['federal reserve', 'executive officer'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['new hampshire', 'nuclear power plant']\n",
      "['nuclear power plant'] \n",
      "\n",
      "['state official', 'sexual abuse', 'false information', 'mental health']\n",
      "['state official', 'sexual abuse', 'false information', 'mental health'] \n",
      "\n",
      "['state department', 'public health', 'propose regulation', 'propose regulation']\n",
      "['state department', 'public health', 'propose regulation', 'propose regulation'] \n",
      "\n",
      "['deny claim', 'hong kong', 'hong kong']\n",
      "['deny claim'] \n",
      "\n",
      "['nuclear regulatory commission', 'energy management', 'energy policy']\n",
      "['nuclear regulatory commission', 'energy management', 'energy policy'] \n",
      "\n",
      "['executive officer', 'new york']\n",
      "['executive officer'] \n",
      "\n",
      "['government regulation', 'fuel economy']\n",
      "['government regulation', 'fuel economy'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['medical examiner']\n",
      "['medical examiner'] \n",
      "\n",
      "['executive office']\n",
      "['executive office'] \n",
      "\n",
      "['tax cut']\n",
      "['tax cut'] \n",
      "\n",
      "['government regulation', 'criminal justice', 'human service', 'urban development', 'natural resource', 'public safety', 'health care', 'state administration']\n",
      "['government regulation', 'criminal justice', 'human service', 'urban development', 'natural resource', 'public safety', 'health care', 'state administration'] \n",
      "\n",
      "['homeless program']\n",
      "['homeless program'] \n",
      "\n",
      "['good interest', 'kansas city']\n",
      "[] \n",
      "\n",
      "['mental health', 'mental health', 'basic research', 'new york', 'new york', 'national institute', 'mental health']\n",
      "['mental health', 'mental health', 'basic research', 'mental health'] \n",
      "\n",
      "['federal law', 'federal reserve', 'other security', 'federal reserve']\n",
      "['federal law', 'federal reserve', 'other security', 'federal reserve'] \n",
      "\n",
      "['retail store', 'security firm']\n",
      "['retail store', 'security firm'] \n",
      "\n",
      "['new hampshire']\n",
      "[] \n",
      "\n",
      "['public access']\n",
      "['public access'] \n",
      "\n",
      "['federal reserve', 'federal regulation', 'federal reserve', 'regulatory body', 'world war ii']\n",
      "['federal reserve', 'federal regulation', 'federal reserve', 'regulatory body'] \n",
      "\n",
      "['state regulation']\n",
      "['state regulation'] \n",
      "\n",
      "['propose transaction', 'hold company']\n",
      "['propose transaction', 'hold company'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['civil penalty', 'hazardous material']\n",
      "['civil penalty', 'hazardous material'] \n",
      "\n",
      "['government regulation']\n",
      "['government regulation'] \n",
      "\n",
      "['education program', 'warning label', 'task force', 'regulatory relief', 'executive order', 'new regulation', 'regulatory relief', \"reye 's syndrome\"]\n",
      "['education program', 'warning label', 'task force', 'regulatory relief', 'executive order', 'new regulation', 'regulatory relief', \"reye 's syndrome\"] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['state regulation', 'federal government', 'individual state']\n",
      "['state regulation', 'federal government', 'individual state'] \n",
      "\n",
      "['school board']\n",
      "['school board'] \n",
      "\n",
      "['assistance program', 'part time', 'executive director', 'cdbg program']\n",
      "['assistance program', 'part time', 'executive director', 'cdbg program'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['united states', 'other matter']\n",
      "[] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['general counsel', 'tender offer']\n",
      "['general counsel', 'tender offer'] \n",
      "\n",
      "['foreign investment', 'foreign investment']\n",
      "['foreign investment', 'foreign investment'] \n",
      "\n",
      "['seat belt', 'seat belt', 'speed limit', 'motor vehicle']\n",
      "['seat belt', 'seat belt', 'speed limit', 'motor vehicle'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['customer satisfaction']\n",
      "['customer satisfaction'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['new regulation']\n",
      "['new regulation'] \n",
      "\n",
      "['internal revenue service', 'rhode island', 'state department']\n",
      "['internal revenue service', 'state department'] \n",
      "\n",
      "['federal fund', 'public offering']\n",
      "['federal fund', 'public offering'] \n",
      "\n",
      "['public health', 'control regulation', 'public health', 'insurance company']\n",
      "['public health', 'control regulation', 'public health', 'insurance company'] \n",
      "\n",
      "['good faith', 'attorney general']\n",
      "['good faith', 'attorney general'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['former member', 'public facility', 'new regulation']\n",
      "['former member', 'public facility', 'new regulation'] \n",
      "\n",
      "[\"people 's republic\", 'transportation management', 'united states']\n",
      "['transportation management'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['construction project', 'hydroelectric power project']\n",
      "['construction project', 'hydroelectric power project'] \n",
      "\n",
      "['public health', 'ambulatory care', 'public health']\n",
      "['public health', 'ambulatory care', 'public health'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['change regulation', 'desegregation program', 'non profit']\n",
      "['change regulation', 'desegregation program', 'non profit'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['hazardous waste', 'water supply', 'solid waste', 'radioactive waste', 'water resource']\n",
      "['hazardous waste', 'water supply', 'solid waste', 'radioactive waste', 'water resource'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['public safety']\n",
      "['public safety'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['agricultural product', 'west virginia']\n",
      "['agricultural product'] \n",
      "\n",
      "['civil fine', 'environmental service', 'federal regulation', 'waste management', 'environmental damage', 'other document', 'environmental protection agency', 'waste management', 'waste management', 'waste management', 'storage requirement', 'waste management', 'high level', 'federal regulation']\n",
      "['civil fine', 'environmental service', 'federal regulation', 'waste management', 'environmental damage', 'environmental protection agency', 'waste management', 'waste management', 'waste management', 'storage requirement', 'waste management', 'federal regulation'] \n",
      "\n",
      "['law enforcement', 'federal statute']\n",
      "['law enforcement', 'federal statute'] \n",
      "\n",
      "['security measure', 'fire safety']\n",
      "['security measure', 'fire safety'] \n",
      "\n",
      "[]\n",
      "[] \n",
      "\n",
      "['related development', 'public utility']\n",
      "['related development', 'public utility'] \n",
      "\n",
      "['new england']\n",
      "[] \n",
      "\n",
      "['internal revenue service', 'pickup truck']\n",
      "['internal revenue service', 'pickup truck'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check some examples\n",
    "for i in range(0,100):\n",
    "    print(df_regSentsExpand['NounChunkMatchWords'][i])\n",
    "    print(df_regSentsExpand['NounChunkMatchWordsFiltered'][i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regSentsExpand.to_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
