{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import reg-relevant article sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 63 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   ID                       493418 non-null  int64  \n",
      " 1   StartDate                493418 non-null  object \n",
      " 2   Newspaper                493418 non-null  object \n",
      " 3   UncertaintyScore         493418 non-null  float64\n",
      " 4   GIscore                  493418 non-null  float64\n",
      " 5   LMscore                  493418 non-null  float64\n",
      " 6   LSDscore                 493418 non-null  float64\n",
      " 7   DominantNounChunkArea1   493418 non-null  int64  \n",
      " 8   DominantArea1            493418 non-null  int64  \n",
      " 9   UniqueDistinctArea1      493418 non-null  int64  \n",
      " 10  DominantDistinctArea1    493418 non-null  int64  \n",
      " 11  DominantNounChunkArea2   493418 non-null  int64  \n",
      " 12  DominantArea2            493418 non-null  int64  \n",
      " 13  UniqueDistinctArea2      493418 non-null  int64  \n",
      " 14  DominantDistinctArea2    493418 non-null  int64  \n",
      " 15  DominantNounChunkArea3   493418 non-null  int64  \n",
      " 16  DominantArea3            493418 non-null  int64  \n",
      " 17  UniqueDistinctArea3      493418 non-null  int64  \n",
      " 18  DominantDistinctArea3    493418 non-null  int64  \n",
      " 19  DominantNounChunkArea4   493418 non-null  int64  \n",
      " 20  DominantArea4            493418 non-null  int64  \n",
      " 21  UniqueDistinctArea4      493418 non-null  int64  \n",
      " 22  DominantDistinctArea4    493418 non-null  int64  \n",
      " 23  DominantNounChunkArea5   493418 non-null  int64  \n",
      " 24  DominantArea5            493418 non-null  int64  \n",
      " 25  UniqueDistinctArea5      493418 non-null  int64  \n",
      " 26  DominantDistinctArea5    493418 non-null  int64  \n",
      " 27  DominantNounChunkArea6   493418 non-null  int64  \n",
      " 28  DominantArea6            493418 non-null  int64  \n",
      " 29  UniqueDistinctArea6      493418 non-null  int64  \n",
      " 30  DominantDistinctArea6    493418 non-null  int64  \n",
      " 31  DominantNounChunkArea7   493418 non-null  int64  \n",
      " 32  DominantArea7            493418 non-null  int64  \n",
      " 33  UniqueDistinctArea7      493418 non-null  int64  \n",
      " 34  DominantDistinctArea7    493418 non-null  int64  \n",
      " 35  DominantNounChunkArea8   493418 non-null  int64  \n",
      " 36  DominantArea8            493418 non-null  int64  \n",
      " 37  UniqueDistinctArea8      493418 non-null  int64  \n",
      " 38  DominantDistinctArea8    493418 non-null  int64  \n",
      " 39  DominantNounChunkArea9   493418 non-null  int64  \n",
      " 40  DominantArea9            493418 non-null  int64  \n",
      " 41  UniqueDistinctArea9      493418 non-null  int64  \n",
      " 42  DominantDistinctArea9    493418 non-null  int64  \n",
      " 43  DominantNounChunkArea10  493418 non-null  int64  \n",
      " 44  DominantArea10           493418 non-null  int64  \n",
      " 45  UniqueDistinctArea10     493418 non-null  int64  \n",
      " 46  DominantDistinctArea10   493418 non-null  int64  \n",
      " 47  DominantNounChunkArea11  493418 non-null  int64  \n",
      " 48  DominantArea11           493418 non-null  int64  \n",
      " 49  UniqueDistinctArea11     493418 non-null  int64  \n",
      " 50  DominantDistinctArea11   493418 non-null  int64  \n",
      " 51  DominantNounChunkArea12  493418 non-null  int64  \n",
      " 52  DominantArea12           493418 non-null  int64  \n",
      " 53  UniqueDistinctArea12     493418 non-null  int64  \n",
      " 54  DominantDistinctArea12   493418 non-null  int64  \n",
      " 55  DominantNounChunkArea13  493418 non-null  int64  \n",
      " 56  DominantArea13           493418 non-null  int64  \n",
      " 57  UniqueDistinctArea13     493418 non-null  int64  \n",
      " 58  DominantDistinctArea13   493418 non-null  int64  \n",
      " 59  DominantNounChunkArea14  493418 non-null  int64  \n",
      " 60  DominantArea14           493418 non-null  int64  \n",
      " 61  UniqueDistinctArea14     493418 non-null  int64  \n",
      " 62  DominantDistinctArea14   493418 non-null  int64  \n",
      "dtypes: float64(4), int64(57), object(2)\n",
      "memory usage: 237.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_ArticleSentimentScores.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat data\n",
    "df['StartDate']=df['StartDate'].astype('datetime64[ns]')\n",
    "df['Year']=df['StartDate'].dt.year\n",
    "df['Month']=df['StartDate'].dt.month\n",
    "df['Newspaper']=df['Newspaper'].astype('category')\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month   YM\n",
      "0    1985      1    1\n",
      "1    1985      2    2\n",
      "2    1985      3    3\n",
      "3    1985      4    4\n",
      "4    1985      5    5\n",
      "..    ...    ...  ...\n",
      "423  2020      4  424\n",
      "424  2020      5  425\n",
      "425  2020      6  426\n",
      "426  2020      7  427\n",
      "427  2020      8  428\n",
      "\n",
      "[428 rows x 3 columns] \n",
      " 428\n"
     ]
    }
   ],
   "source": [
    "# Create year-month dataframe\n",
    "df_ym=df[['Year','Month']].drop_duplicates().sort_values(['Year','Month']).reset_index(drop=True).reset_index()\n",
    "df_ym['YM']=df_ym['index']+1\n",
    "df_ym['YM']=df_ym['YM'].astype('str')\n",
    "df_ym=df_ym.drop('index',axis=1)\n",
    "print(df_ym,'\\n',len(df_ym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 66 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   ID                       493418 non-null  int64         \n",
      " 1   StartDate                493418 non-null  datetime64[ns]\n",
      " 2   Newspaper                493418 non-null  category      \n",
      " 3   UncertaintyScore         493418 non-null  float64       \n",
      " 4   GIscore                  493418 non-null  float64       \n",
      " 5   LMscore                  493418 non-null  float64       \n",
      " 6   LSDscore                 493418 non-null  float64       \n",
      " 7   DominantNounChunkArea1   493418 non-null  int64         \n",
      " 8   DominantArea1            493418 non-null  int64         \n",
      " 9   UniqueDistinctArea1      493418 non-null  int64         \n",
      " 10  DominantDistinctArea1    493418 non-null  int64         \n",
      " 11  DominantNounChunkArea2   493418 non-null  int64         \n",
      " 12  DominantArea2            493418 non-null  int64         \n",
      " 13  UniqueDistinctArea2      493418 non-null  int64         \n",
      " 14  DominantDistinctArea2    493418 non-null  int64         \n",
      " 15  DominantNounChunkArea3   493418 non-null  int64         \n",
      " 16  DominantArea3            493418 non-null  int64         \n",
      " 17  UniqueDistinctArea3      493418 non-null  int64         \n",
      " 18  DominantDistinctArea3    493418 non-null  int64         \n",
      " 19  DominantNounChunkArea4   493418 non-null  int64         \n",
      " 20  DominantArea4            493418 non-null  int64         \n",
      " 21  UniqueDistinctArea4      493418 non-null  int64         \n",
      " 22  DominantDistinctArea4    493418 non-null  int64         \n",
      " 23  DominantNounChunkArea5   493418 non-null  int64         \n",
      " 24  DominantArea5            493418 non-null  int64         \n",
      " 25  UniqueDistinctArea5      493418 non-null  int64         \n",
      " 26  DominantDistinctArea5    493418 non-null  int64         \n",
      " 27  DominantNounChunkArea6   493418 non-null  int64         \n",
      " 28  DominantArea6            493418 non-null  int64         \n",
      " 29  UniqueDistinctArea6      493418 non-null  int64         \n",
      " 30  DominantDistinctArea6    493418 non-null  int64         \n",
      " 31  DominantNounChunkArea7   493418 non-null  int64         \n",
      " 32  DominantArea7            493418 non-null  int64         \n",
      " 33  UniqueDistinctArea7      493418 non-null  int64         \n",
      " 34  DominantDistinctArea7    493418 non-null  int64         \n",
      " 35  DominantNounChunkArea8   493418 non-null  int64         \n",
      " 36  DominantArea8            493418 non-null  int64         \n",
      " 37  UniqueDistinctArea8      493418 non-null  int64         \n",
      " 38  DominantDistinctArea8    493418 non-null  int64         \n",
      " 39  DominantNounChunkArea9   493418 non-null  int64         \n",
      " 40  DominantArea9            493418 non-null  int64         \n",
      " 41  UniqueDistinctArea9      493418 non-null  int64         \n",
      " 42  DominantDistinctArea9    493418 non-null  int64         \n",
      " 43  DominantNounChunkArea10  493418 non-null  int64         \n",
      " 44  DominantArea10           493418 non-null  int64         \n",
      " 45  UniqueDistinctArea10     493418 non-null  int64         \n",
      " 46  DominantDistinctArea10   493418 non-null  int64         \n",
      " 47  DominantNounChunkArea11  493418 non-null  int64         \n",
      " 48  DominantArea11           493418 non-null  int64         \n",
      " 49  UniqueDistinctArea11     493418 non-null  int64         \n",
      " 50  DominantDistinctArea11   493418 non-null  int64         \n",
      " 51  DominantNounChunkArea12  493418 non-null  int64         \n",
      " 52  DominantArea12           493418 non-null  int64         \n",
      " 53  UniqueDistinctArea12     493418 non-null  int64         \n",
      " 54  DominantDistinctArea12   493418 non-null  int64         \n",
      " 55  DominantNounChunkArea13  493418 non-null  int64         \n",
      " 56  DominantArea13           493418 non-null  int64         \n",
      " 57  UniqueDistinctArea13     493418 non-null  int64         \n",
      " 58  DominantDistinctArea13   493418 non-null  int64         \n",
      " 59  DominantNounChunkArea14  493418 non-null  int64         \n",
      " 60  DominantArea14           493418 non-null  int64         \n",
      " 61  UniqueDistinctArea14     493418 non-null  int64         \n",
      " 62  DominantDistinctArea14   493418 non-null  int64         \n",
      " 63  Year                     493418 non-null  int64         \n",
      " 64  Month                    493418 non-null  int64         \n",
      " 65  YM                       493418 non-null  object        \n",
      "dtypes: category(1), datetime64[ns](1), float64(4), int64(59), object(1)\n",
      "memory usage: 245.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge year-month dataframe\n",
    "df=df.merge(df_ym[['Year','Month','YM']],on=['Year','Month'],how='left').sort_values(['Year','Month']).reset_index(drop=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate categorical sentiment indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'UncertaintyScore':'Uncertaintyscore'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "YM_list=df_ym['YM'].tolist()\n",
    "#print(YM_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function (suppressing constant) to estimate categorical index\n",
    "def estimate_categorical_index(score, area):\n",
    "    df_area=df[df[area]==1].reset_index(drop=True)\n",
    "    FE_OLS=sm.ols(formula=score + ' ~ 0+C(YM)+C(Newspaper)', data=df_area).fit()\n",
    "    #print(FE_OLS.summary())\n",
    "\n",
    "    FE_estimates=pd.DataFrame()\n",
    "    new_var=score.split('score')[0]+'_'+area\n",
    "    FE_estimates[new_var]=FE_OLS.params[0:len(df_ym)]\n",
    "    FE_estimates=FE_estimates.reset_index().rename(columns={'index':'FE'})\n",
    "    FE_estimates['YM']=FE_estimates['FE'].str.split(\"[\",expand=True)[1].str.split(\"]\",expand=True)[0]\n",
    "    \n",
    "    for value in FE_estimates['YM']:\n",
    "        if value not in YM_list:\n",
    "            FE_estimates=FE_estimates[FE_estimates['YM']!=value]\n",
    "    FE_estimates=FE_estimates.drop('FE',axis=1)\n",
    "    \n",
    "    return FE_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for different classification approaches\n",
    "area_range=15\n",
    "area_list=[]\n",
    "for i in range(1,area_range):\n",
    "    var1='DominantNounChunkArea'+str(i)\n",
    "    area_list.append(var1)\n",
    "    var2='DominantArea'+str(i)\n",
    "    area_list.append(var2)\n",
    "    var3='UniqueDistinctArea'+str(i)\n",
    "    area_list.append(var3)\n",
    "    var4='DominantDistinctArea'+str(i)\n",
    "    area_list.append(var4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define another function (with constant) to estimate categorical index\n",
    "def estimate_categorical_index_constant(score, area):\n",
    "    df_area=df[df[area]==1].reset_index(drop=True)\n",
    "    FE_OLS=sm.ols(formula=score + ' ~ C(YM)+C(Newspaper)', data=df_area).fit()\n",
    "    #print(FE_OLS.summary())\n",
    "\n",
    "    FE_estimates=pd.DataFrame()\n",
    "    new_var=score.split('score')[0]+'_'+area\n",
    "    FE_estimates['coef']=FE_OLS.params[0:len(df_ym)]\n",
    "    FE_estimates=FE_estimates.reset_index().rename(columns={'index':'FE'})\n",
    "    \n",
    "    for value in FE_estimates['FE']:\n",
    "        if ('YM' not in value) & ('Intercept' not in value):\n",
    "            FE_estimates=FE_estimates[FE_estimates['YM']!=value]\n",
    "    \n",
    "    intercept=FE_estimates[FE_estimates['FE']=='Intercept']['coef'].values\n",
    "    FE_estimates.loc[FE_estimates['FE']!='Intercept',new_var]=FE_estimates.loc[FE_estimates['FE']!='Intercept','coef']+intercept\n",
    "    FE_estimates.loc[FE_estimates['FE']=='Intercept',new_var]=FE_estimates.loc[FE_estimates['FE']=='Intercept','coef']\n",
    "    FE_estimates.loc[FE_estimates['FE']=='Intercept','FE']='C(YM)[T.1]'\n",
    "    FE_estimates=FE_estimates[['FE',new_var]].reset_index(drop=True)\n",
    "    FE_estimates['YM']=FE_estimates['FE'].str.split(\"T.\",expand=True)[1].str.split(\"]\",expand=True)[0]\n",
    "    FE_estimates=FE_estimates.drop('FE',axis=1)\n",
    "    \n",
    "    return FE_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Uncertainty Index\n",
    "CategoricalUncertaintyIndex=df_ym\n",
    "for area in area_list:\n",
    "    try:\n",
    "        estimates=estimate_categorical_index('Uncertaintyscore', area)\n",
    "        CategoricalUncertaintyIndex=CategoricalUncertaintyIndex.merge(estimates,on='YM',how='left')\n",
    "    except:\n",
    "        print(\"Failed:\",area)\n",
    "        estimates=estimate_categorical_index_constant('Uncertaintyscore', area)\n",
    "        CategoricalUncertaintyIndex=CategoricalUncertaintyIndex.merge(estimates,on='YM',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 428 entries, 0 to 427\n",
      "Data columns (total 59 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Year                                 428 non-null    int64  \n",
      " 1   Month                                428 non-null    int64  \n",
      " 2   YM                                   428 non-null    object \n",
      " 3   Uncertainty_DominantNounChunkArea1   428 non-null    float64\n",
      " 4   Uncertainty_DominantArea1            428 non-null    float64\n",
      " 5   Uncertainty_UniqueDistinctArea1      428 non-null    float64\n",
      " 6   Uncertainty_DominantDistinctArea1    428 non-null    float64\n",
      " 7   Uncertainty_DominantNounChunkArea2   428 non-null    float64\n",
      " 8   Uncertainty_DominantArea2            428 non-null    float64\n",
      " 9   Uncertainty_UniqueDistinctArea2      428 non-null    float64\n",
      " 10  Uncertainty_DominantDistinctArea2    428 non-null    float64\n",
      " 11  Uncertainty_DominantNounChunkArea3   428 non-null    float64\n",
      " 12  Uncertainty_DominantArea3            428 non-null    float64\n",
      " 13  Uncertainty_UniqueDistinctArea3      428 non-null    float64\n",
      " 14  Uncertainty_DominantDistinctArea3    428 non-null    float64\n",
      " 15  Uncertainty_DominantNounChunkArea4   428 non-null    float64\n",
      " 16  Uncertainty_DominantArea4            428 non-null    float64\n",
      " 17  Uncertainty_UniqueDistinctArea4      428 non-null    float64\n",
      " 18  Uncertainty_DominantDistinctArea4    428 non-null    float64\n",
      " 19  Uncertainty_DominantNounChunkArea5   428 non-null    float64\n",
      " 20  Uncertainty_DominantArea5            428 non-null    float64\n",
      " 21  Uncertainty_UniqueDistinctArea5      428 non-null    float64\n",
      " 22  Uncertainty_DominantDistinctArea5    428 non-null    float64\n",
      " 23  Uncertainty_DominantNounChunkArea6   428 non-null    float64\n",
      " 24  Uncertainty_DominantArea6            428 non-null    float64\n",
      " 25  Uncertainty_UniqueDistinctArea6      428 non-null    float64\n",
      " 26  Uncertainty_DominantDistinctArea6    428 non-null    float64\n",
      " 27  Uncertainty_DominantNounChunkArea7   428 non-null    float64\n",
      " 28  Uncertainty_DominantArea7            428 non-null    float64\n",
      " 29  Uncertainty_UniqueDistinctArea7      428 non-null    float64\n",
      " 30  Uncertainty_DominantDistinctArea7    428 non-null    float64\n",
      " 31  Uncertainty_DominantNounChunkArea8   428 non-null    float64\n",
      " 32  Uncertainty_DominantArea8            428 non-null    float64\n",
      " 33  Uncertainty_UniqueDistinctArea8      428 non-null    float64\n",
      " 34  Uncertainty_DominantDistinctArea8    428 non-null    float64\n",
      " 35  Uncertainty_DominantNounChunkArea9   428 non-null    float64\n",
      " 36  Uncertainty_DominantArea9            428 non-null    float64\n",
      " 37  Uncertainty_UniqueDistinctArea9      428 non-null    float64\n",
      " 38  Uncertainty_DominantDistinctArea9    428 non-null    float64\n",
      " 39  Uncertainty_DominantNounChunkArea10  428 non-null    float64\n",
      " 40  Uncertainty_DominantArea10           428 non-null    float64\n",
      " 41  Uncertainty_UniqueDistinctArea10     428 non-null    float64\n",
      " 42  Uncertainty_DominantDistinctArea10   428 non-null    float64\n",
      " 43  Uncertainty_DominantNounChunkArea11  428 non-null    float64\n",
      " 44  Uncertainty_DominantArea11           428 non-null    float64\n",
      " 45  Uncertainty_UniqueDistinctArea11     428 non-null    float64\n",
      " 46  Uncertainty_DominantDistinctArea11   428 non-null    float64\n",
      " 47  Uncertainty_DominantNounChunkArea12  428 non-null    float64\n",
      " 48  Uncertainty_DominantArea12           428 non-null    float64\n",
      " 49  Uncertainty_UniqueDistinctArea12     428 non-null    float64\n",
      " 50  Uncertainty_DominantDistinctArea12   428 non-null    float64\n",
      " 51  Uncertainty_DominantNounChunkArea13  428 non-null    float64\n",
      " 52  Uncertainty_DominantArea13           428 non-null    float64\n",
      " 53  Uncertainty_UniqueDistinctArea13     428 non-null    float64\n",
      " 54  Uncertainty_DominantDistinctArea13   428 non-null    float64\n",
      " 55  Uncertainty_DominantNounChunkArea14  428 non-null    float64\n",
      " 56  Uncertainty_DominantArea14           428 non-null    float64\n",
      " 57  Uncertainty_UniqueDistinctArea14     428 non-null    float64\n",
      " 58  Uncertainty_DominantDistinctArea14   428 non-null    float64\n",
      "dtypes: float64(56), int64(2), object(1)\n",
      "memory usage: 200.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(CategoricalUncertaintyIndex.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  Uncertainty_DominantArea1  Uncertainty_DominantDistinctArea1  \\\n",
      "0  1985      1                   0.708625                           0.673390   \n",
      "1  1985      2                   0.530314                           0.586184   \n",
      "2  1985      3                   0.685743                           0.651077   \n",
      "3  1985      4                   0.616541                           0.597864   \n",
      "4  1985      5                   0.663612                           0.546952   \n",
      "\n",
      "   Uncertainty_DominantArea2  Uncertainty_DominantDistinctArea2  \n",
      "0                   0.548945                           0.635044  \n",
      "1                   0.677661                           0.668489  \n",
      "2                   0.704475                           0.717031  \n",
      "3                   0.621052                           0.613644  \n",
      "4                   0.622346                           0.626820  \n"
     ]
    }
   ],
   "source": [
    "print(CategoricalUncertaintyIndex[['Year','Month','Uncertainty_DominantArea1','Uncertainty_DominantDistinctArea1',\n",
    "                                   'Uncertainty_DominantArea2','Uncertainty_DominantDistinctArea2']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalUncertaintyIndex.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_MonthlyUncertaintyIndex.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical sentiment indexes\n",
    "for dict in ['GI','LM','LSD']:\n",
    "    CategoricalSentimentIndex=df_ym\n",
    "    for area in area_list:\n",
    "        try:\n",
    "            estimates=estimate_categorical_index(dict+'score', area)\n",
    "            CategoricalSentimentIndex=CategoricalSentimentIndex.merge(estimates,on='YM',how='left')\n",
    "        except:\n",
    "            print(\"Failed:\",dict+\":\"+area)\n",
    "            estimates=estimate_categorical_index_constant(dict+'score', area)\n",
    "            CategoricalSentimentIndex=CategoricalSentimentIndex.merge(estimates,on='YM',how='left')        \n",
    "    CategoricalSentimentIndex.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_Monthly'+dict+'Index.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Month  LSD_DominantArea8  LSD_DominantDistinctArea8  \\\n",
      "0  1985      1           0.514461                   0.392215   \n",
      "1  1985      2           0.491890                   0.684705   \n",
      "2  1985      3           0.073573                  -0.478702   \n",
      "3  1985      4           0.194892                   0.715342   \n",
      "4  1985      5           0.487910                   0.665488   \n",
      "\n",
      "   LSD_DominantArea8  LSD_DominantDistinctArea8  \n",
      "0           0.514461                   0.392215  \n",
      "1           0.491890                   0.684705  \n",
      "2           0.073573                  -0.478702  \n",
      "3           0.194892                   0.715342  \n",
      "4           0.487910                   0.665488  \n"
     ]
    }
   ],
   "source": [
    "print(CategoricalSentimentIndex[['Year','Month','LSD_DominantArea8','LSD_DominantDistinctArea8',\n",
    "                                'LSD_DominantArea8','LSD_DominantDistinctArea8']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
