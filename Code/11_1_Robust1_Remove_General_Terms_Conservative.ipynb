{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness Check: Remove General Terms from Top 100 Noun Chunks in Each Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ec2-user/nltk_data',\n",
       " '/home/ec2-user/SageMaker/.conda/envs/my_py/nltk_data',\n",
       " '/home/ec2-user/SageMaker/.conda/envs/my_py/share/nltk_data',\n",
       " '/home/ec2-user/SageMaker/.conda/envs/my_py/lib/nltk_data',\n",
       " '/usr/share/nltk_data',\n",
       " '/usr/local/share/nltk_data',\n",
       " '/usr/lib/nltk_data',\n",
       " '/usr/local/lib/nltk_data']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.data.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Regulatory Sections and Noun Chunks with Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10645 entries, 0 to 10644\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   nc_code      10645 non-null  int64 \n",
      " 1   noun_chunks  10645 non-null  object\n",
      " 2   rin          10645 non-null  object\n",
      " 3   area         10185 non-null  object\n",
      " 4   area_no      10645 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 415.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Noun chunks with areas\n",
    "nounchunks_area=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/DictionaryOfRegulatoryNounChunks.csv')\n",
    "print(nounchunks_area.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nc_code</th>\n",
       "      <th>noun_chunks</th>\n",
       "      <th>rin</th>\n",
       "      <th>area</th>\n",
       "      <th>area_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>180-day exclusivity</td>\n",
       "      <td>0910-AC11</td>\n",
       "      <td>{1}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1983 amendment</td>\n",
       "      <td>2115-AB72</td>\n",
       "      <td>{2}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1988 amendment</td>\n",
       "      <td>1205-AB05</td>\n",
       "      <td>{4}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1990 farm bill</td>\n",
       "      <td>0584-AB28</td>\n",
       "      <td>{1}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1993 provision</td>\n",
       "      <td>0970-AB32,3206-AG31</td>\n",
       "      <td>{1}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nc_code          noun_chunks                  rin area  area_no\n",
       "0        0  180-day exclusivity            0910-AC11  {1}        1\n",
       "1        1       1983 amendment            2115-AB72  {2}        1\n",
       "2        2       1988 amendment            1205-AB05  {4}        1\n",
       "3        3       1990 farm bill            0584-AB28  {1}        1\n",
       "4        4       1993 provision  0970-AB32,3206-AG31  {1}        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nounchunks_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1385 entries, 0 to 1384\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   noun_chunks      1385 non-null   object \n",
      " 1   area_no          1385 non-null   int64  \n",
      " 2   area_name        1385 non-null   object \n",
      " 3   remove_dda_less  258 non-null    float64\n",
      " 4   remove_dda_more  449 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 54.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove area-specific general terms\n",
    "nounchunks_remove=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/Top 100 Area-specific Noun Chunks Removed.csv')\n",
    "print(nounchunks_remove.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    258\n",
      "Name: remove_dda, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Specify which removal appraoch to use\n",
    "nounchunks_remove=nounchunks_remove.rename(columns={'remove_dda_less':'remove_dda'})\n",
    "print(nounchunks_remove['remove_dda'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10645 entries, 0 to 10644\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   nc_code      10645 non-null  int64  \n",
      " 1   noun_chunks  10645 non-null  object \n",
      " 2   rin          10645 non-null  object \n",
      " 3   area         10185 non-null  object \n",
      " 4   area_no      10645 non-null  int64  \n",
      " 5   remove_dda   258 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 582.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge\n",
    "nounchunks_area=nounchunks_area.merge(nounchunks_remove[['noun_chunks','remove_dda']],on='noun_chunks',how='left')\n",
    "print(nounchunks_area.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9927\n"
     ]
    }
   ],
   "source": [
    "# Convert to dictionary\n",
    "nounchunks_area=nounchunks_area[(nounchunks_area['area_no']>0) & (nounchunks_area['remove_dda']!=1)].set_index('noun_chunks')\n",
    "nounchunks_area_dict=nounchunks_area.to_dict()['area']\n",
    "print(len(nounchunks_area_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           822737 non-null  object\n",
      " 1   RegSentsExpand               822737 non-null  object\n",
      " 2   NounChunksMatch              822737 non-null  int64 \n",
      " 3   NounChunkMatchWords          822737 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  822737 non-null  object\n",
      " 5   NounChunkMatchFiltered       822737 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 37.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Expanded reg sentences with matched noun chunks\n",
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   ID      788516 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 6.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated articles\n",
    "IDs_nodup=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/IDs_no_duplicates.csv')\n",
    "print(IDs_nodup.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           788516 non-null  int64 \n",
      " 1   RegSentsExpand               788516 non-null  object\n",
      " 2   NounChunksMatch              788516 non-null  int64 \n",
      " 3   NounChunkMatchWords          788516 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  788516 non-null  object\n",
      " 5   NounChunkMatchFiltered       788516 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 36.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_regSentsExpand['ID']=df_regSentsExpand['ID'].astype('int64')\n",
    "df_regSentsExpand=IDs_nodup.merge(df_regSentsExpand,on='ID',how='left').reset_index(drop=True)\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           493418 non-null  int64 \n",
      " 1   RegSentsExpand               493418 non-null  object\n",
      " 2   NounChunksMatch              493418 non-null  int64 \n",
      " 3   NounChunkMatchWords          493418 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object\n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 22.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Refine to reg relevant articles\n",
    "df_regSentsExpandRelevant=df_regSentsExpand[df_regSentsExpand['NounChunkMatchFiltered']>0].reset_index(drop=True)\n",
    "print(df_regSentsExpandRelevant.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Link Expanded Reg Sentences to Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 4: dominant distinct area (dda): use the dominant areas from area-specific noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           493418 non-null  int64 \n",
      " 1   RegSentsExpand               493418 non-null  object\n",
      " 2   NounChunksMatch              493418 non-null  int64 \n",
      " 3   NounChunkMatchWords          493418 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object\n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64 \n",
      " 6   AllDistinctAreas             493418 non-null  object\n",
      " 7   DistinctAreaCount            493418 non-null  object\n",
      " 8   DominantDistinctArea         493418 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 33.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_regSentsExpandRelevant['AllDistinctAreas']=''\n",
    "df_regSentsExpandRelevant['DistinctAreaCount']=''\n",
    "df_regSentsExpandRelevant['DominantDistinctArea']=''\n",
    "for i in range(0, len(df_regSentsExpandRelevant)):\n",
    "    nounchunks=df_regSentsExpandRelevant['NounChunkMatchWordsFiltered'][i]\n",
    "    area_list=[]\n",
    "    for nc in nounchunks:\n",
    "        if nc in nounchunks_area_dict:\n",
    "            area=sorted(literal_eval(nounchunks_area_dict[nc]))\n",
    "            if len(area)==1:\n",
    "                area_list=area_list+area    \n",
    "    \n",
    "    area_count=Counter(area_list).most_common()\n",
    "    dominant_area=[j for j in Counter(area_list).keys() if area_list.count(j)==max(Counter(area_list).values())]\n",
    "    df_regSentsExpandRelevant['AllDistinctAreas'][i]=area_list\n",
    "    df_regSentsExpandRelevant['DistinctAreaCount'][i]=area_count\n",
    "    df_regSentsExpandRelevant['DominantDistinctArea'][i]=dominant_area\n",
    "print(df_regSentsExpandRelevant.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                     RegSentsExpand  \\\n",
      "0   292620682  Now, one hopes, more attention will be paid to...   \n",
      "1   307490698  His economic program as a candidate in the Rep...   \n",
      "2   307420103  As the Bank of New England hearings suggest, t...   \n",
      "3   307576786  The Justice Department contends that the Eight...   \n",
      "4  1944990599  \"The remittances from drivers alone reach almo...   \n",
      "\n",
      "   NounChunksMatch                                NounChunkMatchWords  \\\n",
      "0                8  [land use, civil right, land use, land use, lo...   \n",
      "1                2                                 [tax cut, tax cut]   \n",
      "2               10  [new england, bank hold company, new england, ...   \n",
      "3                4  [civil action, criminal activity, civil claim,...   \n",
      "4                1                            [government regulation]   \n",
      "\n",
      "                         NounChunkMatchWordsFiltered  NounChunkMatchFiltered  \\\n",
      "0  [land use, civil right, land use, land use, pu...                       7   \n",
      "1                                 [tax cut, tax cut]                       2   \n",
      "2  [bank hold company, real estate, net worth, mu...                       4   \n",
      "3     [civil action, criminal activity, civil claim]                       3   \n",
      "4                            [government regulation]                       1   \n",
      "\n",
      "  AllDistinctAreas DistinctAreaCount DominantDistinctArea  \n",
      "0        [5, 5, 5]          [(5, 3)]                  [5]  \n",
      "1           [7, 7]          [(7, 2)]                  [7]  \n",
      "2               []                []                   []  \n",
      "3              [4]          [(4, 1)]                  [4]  \n",
      "4               []                []                   []  \n"
     ]
    }
   ],
   "source": [
    "print(df_regSentsExpandRelevant.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regSentsExpandRelevant.to_pickle('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegSentsExpand_NounChunks_Area_Robust1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtered Noun Chunk Occurences by Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           493418 non-null  int64 \n",
      " 1   RegSentsExpand               493418 non-null  object\n",
      " 2   NounChunksMatch              493418 non-null  int64 \n",
      " 3   NounChunkMatchWords          493418 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object\n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64 \n",
      " 6   AllDistinctAreas             493418 non-null  object\n",
      " 7   DistinctAreaCount            493418 non-null  object\n",
      " 8   DominantDistinctArea         493418 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 33.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reg relevant articles\n",
    "df_regSentsExpandRelevant=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegSentsExpand_NounChunks_Area_Robust1.pkl')\n",
    "print(df_regSentsExpandRelevant.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10645 entries, 0 to 10644\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Noun Chunks  10645 non-null  object\n",
      " 1   Occurences   10645 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 166.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Filtered noun chunk occurences across regulation-related articles\n",
    "df_nounchunk_occurences=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_FilteredNounChunkOccurences.csv')\n",
    "print(df_nounchunk_occurences.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Dummies by dominant distinct area (dda)\n",
    "for i in range(1,15):\n",
    "    var='DominantDistinctArea'+str(i)\n",
    "    df_regSentsExpandRelevant[var]=0\n",
    "    for j in range(0, len(df_regSentsExpandRelevant)):\n",
    "        if i in df_regSentsExpandRelevant['DominantDistinctArea'][j]:\n",
    "            df_regSentsExpandRelevant[var][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Noun Chunks  Occurences  Occurences_dda1  \\\n",
      "0                   new regulation       29880              NaN   \n",
      "1               federal regulation       22168           3242.0   \n",
      "2                      health care       17897           5083.0   \n",
      "3                      real estate       17401            541.0   \n",
      "4                  federal reserve       16590            189.0   \n",
      "...                            ...         ...              ...   \n",
      "10640  mercury contain thermometer           1              NaN   \n",
      "10641                 abandon area           1              NaN   \n",
      "10642                     deep gas           1              NaN   \n",
      "10643               float facility           1              NaN   \n",
      "10644              secondary payer           1              NaN   \n",
      "\n",
      "       Occurences_dda2  Occurences_dda3  Occurences_dda4  Occurences_dda5  \\\n",
      "0                  NaN              NaN              NaN              NaN   \n",
      "1               1271.0           1763.0            597.0           3201.0   \n",
      "2                831.0            529.0            452.0            888.0   \n",
      "3                482.0            268.0            188.0            874.0   \n",
      "4                140.0             85.0             68.0            160.0   \n",
      "...                ...              ...              ...              ...   \n",
      "10640              NaN              NaN              NaN              1.0   \n",
      "10641              NaN              NaN              1.0              NaN   \n",
      "10642              NaN              NaN              NaN              1.0   \n",
      "10643              1.0              NaN              NaN              1.0   \n",
      "10644              NaN              NaN              NaN              NaN   \n",
      "\n",
      "       Occurences_dda6  Occurences_dda7  Occurences_dda8  Occurences_dda9  \\\n",
      "0                  NaN              NaN              NaN              NaN   \n",
      "1                473.0           2786.0            846.0            219.0   \n",
      "2                193.0           2623.0            466.0             78.0   \n",
      "3                103.0           6910.0           1144.0            188.0   \n",
      "4                 37.0          16254.0            698.0             48.0   \n",
      "...                ...              ...              ...              ...   \n",
      "10640              NaN              NaN              NaN              NaN   \n",
      "10641              NaN              NaN              NaN              NaN   \n",
      "10642              NaN              NaN              NaN              NaN   \n",
      "10643              NaN              NaN              NaN              NaN   \n",
      "10644              NaN              NaN              NaN              NaN   \n",
      "\n",
      "       Occurences_dda10  Occurences_dda11  Occurences_dda12  Occurences_dda13  \\\n",
      "0                   NaN               NaN               NaN               NaN   \n",
      "1                 158.0             330.0             167.0            1045.0   \n",
      "2                  76.0              83.0             175.0            1219.0   \n",
      "3                  23.0              86.0              73.0            1680.0   \n",
      "4                   6.0              13.0               9.0             432.0   \n",
      "...                 ...               ...               ...               ...   \n",
      "10640               NaN               NaN               NaN               NaN   \n",
      "10641               NaN               NaN               NaN               NaN   \n",
      "10642               NaN               NaN               NaN               1.0   \n",
      "10643               NaN               NaN               NaN               NaN   \n",
      "10644               NaN               NaN               NaN               1.0   \n",
      "\n",
      "       Occurences_dda14  \n",
      "0                   NaN  \n",
      "1                 117.0  \n",
      "2                  58.0  \n",
      "3                  68.0  \n",
      "4                   5.0  \n",
      "...                 ...  \n",
      "10640               NaN  \n",
      "10641               NaN  \n",
      "10642               NaN  \n",
      "10643               NaN  \n",
      "10644               NaN  \n",
      "\n",
      "[10645 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtered noun chunks across regulation-related articles by area\n",
    "for i in range(1,15):\n",
    "    allDistinctAreas=[]\n",
    "    for allArea in df_regSentsExpandRelevant[df_regSentsExpandRelevant['DominantDistinctArea'+str(i)]==1]['NounChunkMatchWordsFiltered']:\n",
    "        distinctArea=[nc for nc in allArea if nc in nounchunks_area_dict]\n",
    "        allDistinctAreas=allDistinctAreas+distinctArea\n",
    "    allDistinctAreaCount=Counter(allDistinctAreas)\n",
    "    var_name='Occurences_dda'+str(i)\n",
    "    df_MatchWords = pd.DataFrame(allDistinctAreaCount.items(),columns = ['Noun Chunks',var_name])\n",
    "    df_nounchunk_occurences=df_nounchunk_occurences.merge(df_MatchWords,on='Noun Chunks',how='outer')\n",
    "print(df_nounchunk_occurences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nounchunk_occurences.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_FilteredNounChunkOccurences_Robust1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aggregate sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           493418 non-null  int64 \n",
      " 1   RegSentsExpand               493418 non-null  object\n",
      " 2   NounChunksMatch              493418 non-null  int64 \n",
      " 3   NounChunkMatchWords          493418 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object\n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64 \n",
      " 6   AllDistinctAreas             493418 non-null  object\n",
      " 7   DistinctAreaCount            493418 non-null  object\n",
      " 8   DominantDistinctArea         493418 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 33.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reg relevant articles\n",
    "df_regSentsExpandRelevant=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegSentsExpand_NounChunks_Area_Robust1.pkl')\n",
    "print(df_regSentsExpandRelevant.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   ID             822737 non-null  object        \n",
      " 1   Title          822737 non-null  object        \n",
      " 2   Type           822737 non-null  object        \n",
      " 3   StartDate      822737 non-null  datetime64[ns]\n",
      " 4   EndDate        822737 non-null  object        \n",
      " 5   Text           822737 non-null  object        \n",
      " 6   TextWordCount  822737 non-null  object        \n",
      " 7   PubTitle       822737 non-null  object        \n",
      " 8   SourceType     822737 non-null  object        \n",
      " 9   Year           822737 non-null  int64         \n",
      " 10  Month          822737 non-null  int64         \n",
      " 11  Newspaper      822737 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(9)\n",
      "memory usage: 75.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# All news data\n",
    "allNews=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/parsed_xml.pkl')\n",
    "print(allNews.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 493418 entries, 0 to 493417\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   ID                           493418 non-null  int64         \n",
      " 1   RegSentsExpand               493418 non-null  object        \n",
      " 2   NounChunksMatch              493418 non-null  int64         \n",
      " 3   NounChunkMatchWords          493418 non-null  object        \n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object        \n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64         \n",
      " 6   AllDistinctAreas             493418 non-null  object        \n",
      " 7   DistinctAreaCount            493418 non-null  object        \n",
      " 8   DominantDistinctArea         493418 non-null  object        \n",
      " 9   Title                        493418 non-null  object        \n",
      " 10  Type                         493418 non-null  object        \n",
      " 11  SourceType                   493418 non-null  object        \n",
      " 12  StartDate                    493418 non-null  datetime64[ns]\n",
      " 13  Newspaper                    493418 non-null  object        \n",
      " 14  Year                         493418 non-null  int64         \n",
      " 15  Month                        493418 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(5), object(10)\n",
      "memory usage: 64.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge with all news data\n",
    "allNews['ID']=allNews['ID'].astype('int64')\n",
    "df=df_regSentsExpandRelevant.merge(allNews[['ID','Title','Type','SourceType','StartDate','Newspaper','Year','Month']],\n",
    "                                  on='ID',how='left')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for different approaches\n",
    "area_range=15    # Number of areas + 1\n",
    "col_list=[]\n",
    "for i in range(1,area_range):\n",
    "    var='DominantDistinctArea'+str(i)\n",
    "    col_list.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Dummies by dominant distinct area (dda)\n",
    "for i in range(1,area_range):\n",
    "    var='DominantDistinctArea'+str(i)\n",
    "    df[var]=0\n",
    "    for j in range(0, len(df)):\n",
    "        if i in df['DominantDistinctArea'][j]:\n",
    "            df[var][j]=1\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ID                493418 non-null  int64  \n",
      " 1   StartDate         493418 non-null  object \n",
      " 2   Newspaper         493418 non-null  object \n",
      " 3   UncertaintyScore  493418 non-null  float64\n",
      " 4   GIscore           493418 non-null  float64\n",
      " 5   LMscore           493418 non-null  float64\n",
      " 6   LSDscore          493418 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 26.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge with sentiment scores\n",
    "sentimentScores=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/RegRelevant_ArticleSentimentScores.csv')\n",
    "print(sentimentScores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df['ID']=df['ID'].astype('int64')\n",
    "df2=df.merge(sentimentScores[['ID','UncertaintyScore','GIscore','LMscore','LSDscore']],on='ID',how='left')\n",
    "#print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['ID','StartDate','Newspaper','UncertaintyScore','GIscore','LMscore','LSDscore']+col_list].\\\n",
    "    to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_ArticleSentimentScores_Robust1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Monthly article count by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2945 entries, 0 to 2944\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Newspaper               2945 non-null   object\n",
      " 1   Year                    2945 non-null   int64 \n",
      " 2   Month                   2945 non-null   int64 \n",
      " 3   DominantDistinctArea1   2945 non-null   int64 \n",
      " 4   DominantDistinctArea2   2945 non-null   int64 \n",
      " 5   DominantDistinctArea3   2945 non-null   int64 \n",
      " 6   DominantDistinctArea4   2945 non-null   int64 \n",
      " 7   DominantDistinctArea5   2945 non-null   int64 \n",
      " 8   DominantDistinctArea6   2945 non-null   int64 \n",
      " 9   DominantDistinctArea7   2945 non-null   int64 \n",
      " 10  DominantDistinctArea8   2945 non-null   int64 \n",
      " 11  DominantDistinctArea9   2945 non-null   int64 \n",
      " 12  DominantDistinctArea10  2945 non-null   int64 \n",
      " 13  DominantDistinctArea11  2945 non-null   int64 \n",
      " 14  DominantDistinctArea12  2945 non-null   int64 \n",
      " 15  DominantDistinctArea13  2945 non-null   int64 \n",
      " 16  DominantDistinctArea14  2945 non-null   int64 \n",
      "dtypes: int64(16), object(1)\n",
      "memory usage: 391.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Aggregate monthly article counts\n",
    "monthlyAreaCount=df[['Newspaper','Year','Month']+col_list].groupby(['Newspaper','Year','Month']).agg('sum').reset_index()\n",
    "print(monthlyAreaCount.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyAreaCount.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_MonthlyArticleCountByNewspaper_Robust1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construct categorical sentiment indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   ID                      493418 non-null  int64  \n",
      " 1   StartDate               493418 non-null  object \n",
      " 2   Newspaper               493418 non-null  object \n",
      " 3   UncertaintyScore        493418 non-null  float64\n",
      " 4   GIscore                 493418 non-null  float64\n",
      " 5   LMscore                 493418 non-null  float64\n",
      " 6   LSDscore                493418 non-null  float64\n",
      " 7   DominantDistinctArea1   493418 non-null  int64  \n",
      " 8   DominantDistinctArea2   493418 non-null  int64  \n",
      " 9   DominantDistinctArea3   493418 non-null  int64  \n",
      " 10  DominantDistinctArea4   493418 non-null  int64  \n",
      " 11  DominantDistinctArea5   493418 non-null  int64  \n",
      " 12  DominantDistinctArea6   493418 non-null  int64  \n",
      " 13  DominantDistinctArea7   493418 non-null  int64  \n",
      " 14  DominantDistinctArea8   493418 non-null  int64  \n",
      " 15  DominantDistinctArea9   493418 non-null  int64  \n",
      " 16  DominantDistinctArea10  493418 non-null  int64  \n",
      " 17  DominantDistinctArea11  493418 non-null  int64  \n",
      " 18  DominantDistinctArea12  493418 non-null  int64  \n",
      " 19  DominantDistinctArea13  493418 non-null  int64  \n",
      " 20  DominantDistinctArea14  493418 non-null  int64  \n",
      "dtypes: float64(4), int64(15), object(2)\n",
      "memory usage: 79.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_ArticleSentimentScores_Robust1.csv')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat data\n",
    "df['StartDate']=df['StartDate'].astype('datetime64[ns]')\n",
    "df['Year']=df['StartDate'].dt.year\n",
    "df['Month']=df['StartDate'].dt.month\n",
    "df['Newspaper']=df['Newspaper'].astype('category')\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Year  Month   YM\n",
      "0    1985      1    1\n",
      "1    1985      2    2\n",
      "2    1985      3    3\n",
      "3    1985      4    4\n",
      "4    1985      5    5\n",
      "..    ...    ...  ...\n",
      "423  2020      4  424\n",
      "424  2020      5  425\n",
      "425  2020      6  426\n",
      "426  2020      7  427\n",
      "427  2020      8  428\n",
      "\n",
      "[428 rows x 3 columns] \n",
      " 428\n"
     ]
    }
   ],
   "source": [
    "# Create year-month dataframe\n",
    "df_ym=df[['Year','Month']].drop_duplicates().sort_values(['Year','Month']).reset_index(drop=True).reset_index()\n",
    "df_ym['YM']=df_ym['index']+1\n",
    "df_ym['YM']=df_ym['YM'].astype('str')\n",
    "df_ym=df_ym.drop('index',axis=1)\n",
    "print(df_ym,'\\n',len(df_ym))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   ID                      493418 non-null  int64         \n",
      " 1   StartDate               493418 non-null  datetime64[ns]\n",
      " 2   Newspaper               493418 non-null  category      \n",
      " 3   UncertaintyScore        493418 non-null  float64       \n",
      " 4   GIscore                 493418 non-null  float64       \n",
      " 5   LMscore                 493418 non-null  float64       \n",
      " 6   LSDscore                493418 non-null  float64       \n",
      " 7   DominantDistinctArea1   493418 non-null  int64         \n",
      " 8   DominantDistinctArea2   493418 non-null  int64         \n",
      " 9   DominantDistinctArea3   493418 non-null  int64         \n",
      " 10  DominantDistinctArea4   493418 non-null  int64         \n",
      " 11  DominantDistinctArea5   493418 non-null  int64         \n",
      " 12  DominantDistinctArea6   493418 non-null  int64         \n",
      " 13  DominantDistinctArea7   493418 non-null  int64         \n",
      " 14  DominantDistinctArea8   493418 non-null  int64         \n",
      " 15  DominantDistinctArea9   493418 non-null  int64         \n",
      " 16  DominantDistinctArea10  493418 non-null  int64         \n",
      " 17  DominantDistinctArea11  493418 non-null  int64         \n",
      " 18  DominantDistinctArea12  493418 non-null  int64         \n",
      " 19  DominantDistinctArea13  493418 non-null  int64         \n",
      " 20  DominantDistinctArea14  493418 non-null  int64         \n",
      " 21  Year                    493418 non-null  int64         \n",
      " 22  Month                   493418 non-null  int64         \n",
      " 23  YM                      493418 non-null  object        \n",
      "dtypes: category(1), datetime64[ns](1), float64(4), int64(17), object(1)\n",
      "memory usage: 87.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge year-month dataframe\n",
    "df=df.merge(df_ym[['Year','Month','YM']],on=['Year','Month'],how='left').sort_values(['Year','Month']).reset_index(drop=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'UncertaintyScore':'Uncertaintyscore'})\n",
    "YM_list=df_ym['YM'].tolist()\n",
    "#print(YM_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function (suppressing constant) to estimate categorical index\n",
    "def estimate_categorical_index(score, area):\n",
    "    df_area=df[df[area]==1].reset_index(drop=True)\n",
    "    FE_OLS=sm.ols(formula=score + ' ~ 0+C(YM)+C(Newspaper)', data=df_area).fit()\n",
    "    #print(FE_OLS.summary())\n",
    "\n",
    "    FE_estimates=pd.DataFrame()\n",
    "    new_var=score.split('score')[0]+'_'+area\n",
    "    FE_estimates[new_var]=FE_OLS.params[0:len(df_ym)]\n",
    "    FE_estimates=FE_estimates.reset_index().rename(columns={'index':'FE'})\n",
    "    FE_estimates['YM']=FE_estimates['FE'].str.split(\"[\",expand=True)[1].str.split(\"]\",expand=True)[0]\n",
    "    \n",
    "    for value in FE_estimates['YM']:\n",
    "        if value not in YM_list:\n",
    "            FE_estimates=FE_estimates[FE_estimates['YM']!=value]\n",
    "    FE_estimates=FE_estimates.drop('FE',axis=1)\n",
    "    \n",
    "    return FE_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for different classification approaches\n",
    "area_range=15\n",
    "area_list=[]\n",
    "for i in range(1,area_range):\n",
    "    var='DominantDistinctArea'+str(i)\n",
    "    area_list.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Uncertainty Index\n",
    "CategoricalUncertaintyIndex=df_ym\n",
    "for area in area_list:\n",
    "    try:\n",
    "        estimates=estimate_categorical_index('Uncertaintyscore', area)\n",
    "        CategoricalUncertaintyIndex=CategoricalUncertaintyIndex.merge(estimates,on='YM',how='left')\n",
    "    except:\n",
    "        print(\"Failed:\",area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalUncertaintyIndex.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_MonthlyUncertaintyIndex_Robust1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical sentiment indexes\n",
    "for dict in ['GI','LM','LSD']:\n",
    "    CategoricalSentimentIndex=df_ym\n",
    "    for area in area_list:\n",
    "        try:\n",
    "            estimates=estimate_categorical_index(dict+'score', area)\n",
    "            CategoricalSentimentIndex=CategoricalSentimentIndex.merge(estimates,on='YM',how='left')\n",
    "        except:\n",
    "            print(\"Failed:\",dict+\":\"+area)      \n",
    "    CategoricalSentimentIndex.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_Monthly'+dict+'Index_Robust1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
