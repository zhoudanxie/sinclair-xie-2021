{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           822737 non-null  object\n",
      " 1   RegSentsExpand               822737 non-null  object\n",
      " 2   NounChunksMatch              822737 non-null  int64 \n",
      " 3   NounChunkMatchWords          822737 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  822737 non-null  object\n",
      " 5   NounChunkMatchFiltered       822737 non-null  int64 \n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 37.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Regulatory sections with matched noun chunks\n",
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegSentsExpand_NounChunks3.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   ID             822737 non-null  object        \n",
      " 1   Title          822737 non-null  object        \n",
      " 2   Type           822737 non-null  object        \n",
      " 3   StartDate      822737 non-null  datetime64[ns]\n",
      " 4   EndDate        822737 non-null  object        \n",
      " 5   Text           822737 non-null  object        \n",
      " 6   TextWordCount  822737 non-null  object        \n",
      " 7   PubTitle       822737 non-null  object        \n",
      " 8   SourceType     822737 non-null  object        \n",
      " 9   Year           822737 non-null  int64         \n",
      " 10  Month          822737 non-null  int64         \n",
      " 11  Newspaper      822737 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(9)\n",
      "memory usage: 75.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# All news article metadata\n",
    "allNews=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/parsed_xml.pkl')\n",
    "print(allNews.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(allNews['PubTitle'].value_counts())\n",
    "# print(allNews['PubTitle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall Street Journal    251983\n",
      "New York Times         125270\n",
      "Los Angeles Times      121406\n",
      "The Washington Post    116772\n",
      "Chicago Tribune         90023\n",
      "Boston Globe            78922\n",
      "USA Today               38361\n",
      "Name: Newspaper, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(allNews['Newspaper'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 822737 entries, 0 to 822736\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   ID                           822737 non-null  object        \n",
      " 1   RegSentsExpand               822737 non-null  object        \n",
      " 2   NounChunksMatch              822737 non-null  int64         \n",
      " 3   NounChunkMatchWords          822737 non-null  object        \n",
      " 4   NounChunkMatchWordsFiltered  822737 non-null  object        \n",
      " 5   NounChunkMatchFiltered       822737 non-null  int64         \n",
      " 6   Title                        822737 non-null  object        \n",
      " 7   StartDate                    822737 non-null  datetime64[ns]\n",
      " 8   Newspaper                    822737 non-null  object        \n",
      " 9   Year                         822737 non-null  int64         \n",
      " 10  Month                        822737 non-null  int64         \n",
      " 11  Type                         822737 non-null  object        \n",
      " 12  SourceType                   822737 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(8)\n",
      "memory usage: 87.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge with metadata\n",
    "df=df_regSentsExpand.merge(allNews[['ID','Title','StartDate','Newspaper','Year','Month','Type','SourceType']],\n",
    "                           on='ID',how='left')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   ID      788516 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 6.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated articles\n",
    "IDs_nodup=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/IDs_no_duplicates.csv')\n",
    "print(IDs_nodup.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 13 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   ID                           788516 non-null  int64         \n",
      " 1   RegSentsExpand               788516 non-null  object        \n",
      " 2   NounChunksMatch              788516 non-null  int64         \n",
      " 3   NounChunkMatchWords          788516 non-null  object        \n",
      " 4   NounChunkMatchWordsFiltered  788516 non-null  object        \n",
      " 5   NounChunkMatchFiltered       788516 non-null  int64         \n",
      " 6   Title                        788516 non-null  object        \n",
      " 7   StartDate                    788516 non-null  datetime64[ns]\n",
      " 8   Newspaper                    788516 non-null  object        \n",
      " 9   Year                         788516 non-null  int64         \n",
      " 10  Month                        788516 non-null  int64         \n",
      " 11  Type                         788516 non-null  object        \n",
      " 12  SourceType                   788516 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(5), object(7)\n",
      "memory usage: 78.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df['ID']=df['ID'].astype('int64')\n",
    "df=IDs_nodup.merge(df,on='ID',how='left').reset_index(drop=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reg relevent articles (unfiltered): 553586\n",
      "# of reg relevent articles (filtered): 493418\n"
     ]
    }
   ],
   "source": [
    "# Reg relevant articles\n",
    "print(\"# of reg relevent articles (unfiltered):\",df[df['NounChunksMatch']!=0]['ID'].nunique())    # Unfiltered version of noun chunks\n",
    "\n",
    "print(\"# of reg relevent articles (filtered):\",df[df['NounChunkMatchFiltered']!=0]['ID'].nunique())    # Filtered version of noun chunks\n",
    "#print(df['NounChunkMatchFiltered'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 788516 entries, 0 to 788515\n",
      "Data columns (total 14 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   ID                           788516 non-null  int64         \n",
      " 1   RegSentsExpand               788516 non-null  object        \n",
      " 2   NounChunksMatch              788516 non-null  int64         \n",
      " 3   NounChunkMatchWords          788516 non-null  object        \n",
      " 4   NounChunkMatchWordsFiltered  788516 non-null  object        \n",
      " 5   NounChunkMatchFiltered       788516 non-null  int64         \n",
      " 6   Title                        788516 non-null  object        \n",
      " 7   StartDate                    788516 non-null  datetime64[ns]\n",
      " 8   Newspaper                    788516 non-null  object        \n",
      " 9   Year                         788516 non-null  int64         \n",
      " 10  Month                        788516 non-null  int64         \n",
      " 11  Type                         788516 non-null  object        \n",
      " 12  SourceType                   788516 non-null  object        \n",
      " 13  RegRelevance                 493418 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(5), object(7)\n",
      "memory usage: 84.2+ MB\n",
      "None\n",
      "# of reg relevant articles: 493418\n"
     ]
    }
   ],
   "source": [
    "# Use filtered noun chunk matches to define reg relevance\n",
    "df.loc[df['NounChunkMatchFiltered']!=0,'RegRelevance']=1\n",
    "print(df.info())\n",
    "print(\"# of reg relevant articles:\",df[df['RegRelevance']==1]['ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2945 entries, 0 to 2944\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Newspaper     2945 non-null   object \n",
      " 1   Year          2945 non-null   int64  \n",
      " 2   Month         2945 non-null   int64  \n",
      " 3   RegRelevance  2945 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 92.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Aggregate reg-relevant article count by month\n",
    "monthlyCount=df[['Newspaper','Year','Month','RegRelevance']].groupby(['Newspaper','Year','Month']).agg('sum').reset_index()\n",
    "print(monthlyCount.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Newspaper  Year  Month  RegRelevance\n",
      "0            Boston Globe  1985      1          83.0\n",
      "1            Boston Globe  1985      2          91.0\n",
      "2            Boston Globe  1985      3         107.0\n",
      "3            Boston Globe  1985      4          93.0\n",
      "4            Boston Globe  1985      5         113.0\n",
      "...                   ...   ...    ...           ...\n",
      "2940  Wall Street Journal  2020      4         380.0\n",
      "2941  Wall Street Journal  2020      5         364.0\n",
      "2942  Wall Street Journal  2020      6         381.0\n",
      "2943  Wall Street Journal  2020      7         377.0\n",
      "2944  Wall Street Journal  2020      8         369.0\n",
      "\n",
      "[2945 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(monthlyCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyCount.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Reg Relevance/RegRelevant_MonthlyArticleCount.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
