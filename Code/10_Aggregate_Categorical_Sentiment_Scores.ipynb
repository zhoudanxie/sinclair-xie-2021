{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import articles with area codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 15 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ID                           493418 non-null  int64 \n",
      " 1   RegSentsExpand               493418 non-null  object\n",
      " 2   NounChunksMatch              493418 non-null  int64 \n",
      " 3   NounChunkMatchWords          493418 non-null  object\n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object\n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64 \n",
      " 6   DominantNounChunk            493418 non-null  object\n",
      " 7   DominantNounChunkArea        493418 non-null  object\n",
      " 8   AllAreas                     493418 non-null  object\n",
      " 9   AreaCount                    493418 non-null  object\n",
      " 10  DominantArea                 493418 non-null  object\n",
      " 11  AllDistinctAreas             493418 non-null  object\n",
      " 12  UniqueDistinctAreas          493418 non-null  object\n",
      " 13  DistinctAreaCount            493418 non-null  object\n",
      " 14  DominantDistinctArea         493418 non-null  object\n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 56.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reg relevant articles\n",
    "df_regSentsExpandRelevant=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegSentsExpand_NounChunks_Area.pkl')\n",
    "print(df_regSentsExpandRelevant.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 822737 entries, 0 to 822736\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   ID             822737 non-null  object        \n",
      " 1   Title          822737 non-null  object        \n",
      " 2   Type           822737 non-null  object        \n",
      " 3   StartDate      822737 non-null  datetime64[ns]\n",
      " 4   EndDate        822737 non-null  object        \n",
      " 5   Text           822737 non-null  object        \n",
      " 6   TextWordCount  822737 non-null  object        \n",
      " 7   PubTitle       822737 non-null  object        \n",
      " 8   SourceType     822737 non-null  object        \n",
      " 9   Year           822737 non-null  int64         \n",
      " 10  Month          822737 non-null  int64         \n",
      " 11  Newspaper      822737 non-null  object        \n",
      "dtypes: datetime64[ns](1), int64(2), object(9)\n",
      "memory usage: 75.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# All news data\n",
    "allNews=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/parsed_xml.pkl')\n",
    "print(allNews.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 493418 entries, 0 to 493417\n",
      "Data columns (total 22 columns):\n",
      " #   Column                       Non-Null Count   Dtype         \n",
      "---  ------                       --------------   -----         \n",
      " 0   ID                           493418 non-null  int64         \n",
      " 1   RegSentsExpand               493418 non-null  object        \n",
      " 2   NounChunksMatch              493418 non-null  int64         \n",
      " 3   NounChunkMatchWords          493418 non-null  object        \n",
      " 4   NounChunkMatchWordsFiltered  493418 non-null  object        \n",
      " 5   NounChunkMatchFiltered       493418 non-null  int64         \n",
      " 6   DominantNounChunk            493418 non-null  object        \n",
      " 7   DominantNounChunkArea        493418 non-null  object        \n",
      " 8   AllAreas                     493418 non-null  object        \n",
      " 9   AreaCount                    493418 non-null  object        \n",
      " 10  DominantArea                 493418 non-null  object        \n",
      " 11  AllDistinctAreas             493418 non-null  object        \n",
      " 12  UniqueDistinctAreas          493418 non-null  object        \n",
      " 13  DistinctAreaCount            493418 non-null  object        \n",
      " 14  DominantDistinctArea         493418 non-null  object        \n",
      " 15  Title                        493418 non-null  object        \n",
      " 16  Type                         493418 non-null  object        \n",
      " 17  SourceType                   493418 non-null  object        \n",
      " 18  StartDate                    493418 non-null  datetime64[ns]\n",
      " 19  Newspaper                    493418 non-null  object        \n",
      " 20  Year                         493418 non-null  int64         \n",
      " 21  Month                        493418 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(5), object(16)\n",
      "memory usage: 86.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge with all news data\n",
    "allNews['ID']=allNews['ID'].astype('int64')\n",
    "df=df_regSentsExpandRelevant.merge(allNews[['ID','Title','Type','SourceType','StartDate','Newspaper','Year','Month']],\n",
    "                                  on='ID',how='left')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News    493418\n",
      "Name: Type, dtype: int64\n",
      "Newspapers    493418\n",
      "Name: SourceType, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Type'].value_counts())\n",
    "print(df['SourceType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Refine to sourcetype=newspaper\n",
    "# df=df[df['SourceType']=='Newspapers'].reset_index(drop=True)\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                     RegSentsExpand  \\\n",
      "0   292620682  Now, one hopes, more attention will be paid to...   \n",
      "1   307490698  His economic program as a candidate in the Rep...   \n",
      "2   307420103  As the Bank of New England hearings suggest, t...   \n",
      "3   307576786  The Justice Department contends that the Eight...   \n",
      "4  1944990599  \"The remittances from drivers alone reach almo...   \n",
      "\n",
      "   NounChunksMatch                                NounChunkMatchWords  \\\n",
      "0                8  [land use, civil right, land use, land use, lo...   \n",
      "1                2                                 [tax cut, tax cut]   \n",
      "2               10  [new england, bank hold company, new england, ...   \n",
      "3                4  [civil action, criminal activity, civil claim,...   \n",
      "4                1                            [government regulation]   \n",
      "\n",
      "                         NounChunkMatchWordsFiltered  NounChunkMatchFiltered  \\\n",
      "0  [land use, civil right, land use, land use, pu...                       7   \n",
      "1                                 [tax cut, tax cut]                       2   \n",
      "2  [bank hold company, real estate, net worth, mu...                       4   \n",
      "3     [civil action, criminal activity, civil claim]                       3   \n",
      "4                            [government regulation]                       1   \n",
      "\n",
      "                                   DominantNounChunk DominantNounChunkArea  \\\n",
      "0                                         [land use]                   {5}   \n",
      "1                                          [tax cut]                   {7}   \n",
      "2  [bank hold company, real estate, net worth, mu...     {2, 7, 8, 10, 15}   \n",
      "3     [civil action, criminal activity, civil claim]    {2, 4, 11, 15, 16}   \n",
      "4                            [government regulation]                   {7}   \n",
      "\n",
      "                              AllAreas  \\\n",
      "0  [5, 14, 15, 16, 5, 5, 2, 11, 15, 3]   \n",
      "1                               [7, 7]   \n",
      "2        [7, 8, 2, 8, 10, 7, 15, 7, 8]   \n",
      "3               [4, 2, 15, 16, 11, 15]   \n",
      "4                                  [7]   \n",
      "\n",
      "                                           AreaCount  ... UniqueDistinctAreas  \\\n",
      "0  [(5, 3), (15, 2), (14, 1), (16, 1), (2, 1), (1...  ...          {3, 5, 15}   \n",
      "1                                           [(7, 2)]  ...                 {7}   \n",
      "2         [(7, 3), (8, 3), (2, 1), (10, 1), (15, 1)]  ...                  {}   \n",
      "3        [(15, 2), (4, 1), (2, 1), (16, 1), (11, 1)]  ...                 {4}   \n",
      "4                                           [(7, 1)]  ...                 {7}   \n",
      "\n",
      "           DistinctAreaCount DominantDistinctArea  \\\n",
      "0  [(5, 3), (15, 1), (3, 1)]                  [5]   \n",
      "1                   [(7, 2)]                  [7]   \n",
      "2                         []                   []   \n",
      "3                   [(4, 1)]                  [4]   \n",
      "4                   [(7, 1)]                  [7]   \n",
      "\n",
      "                                               Title  Type  SourceType  \\\n",
      "0  Restoring Rights to Property Owners Supreme Co...  News  Newspapers   \n",
      "1  New Hampshire Awaits Latest Edition of Candida...  News  Newspapers   \n",
      "2                     Fix the Regulatory Process ...  News  Newspapers   \n",
      "3  Justices to Review Civil Property Forfeitures ...  News  Newspapers   \n",
      "4  THE WORLD; A payoff to ending Saudi ban on fem...  News  Newspapers   \n",
      "\n",
      "   StartDate            Newspaper  Year Month  \n",
      "0 1987-07-07    Los Angeles Times  1987     7  \n",
      "1 1992-01-15  The Washington Post  1992     1  \n",
      "2 1991-05-13  The Washington Post  1991     5  \n",
      "3 1993-01-16  The Washington Post  1993     1  \n",
      "4 2017-10-02    Los Angeles Times  2017    10  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dummies for areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns for different approaches\n",
    "col_list=[]\n",
    "for i in range(1,17):\n",
    "    var1='DominantNounChunkArea'+str(i)\n",
    "    col_list.append(var1)\n",
    "    var2='DominantArea'+str(i)\n",
    "    col_list.append(var2)\n",
    "    var3='UniqueDistinctArea'+str(i)\n",
    "    col_list.append(var3)\n",
    "    var4='DominantDistinctArea'+str(i)\n",
    "    col_list.append(var4)\n",
    "col_list.append('DominantNounChunkArea8-9')\n",
    "col_list.append('DominantArea8-9')\n",
    "col_list.append('UniqueDistinctArea8-9')\n",
    "col_list.append('DominantDistinctArea8-9')\n",
    "#print(col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dummies by dominant noun chunk area (dnca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                ID                                     RegSentsExpand  \\\n",
      "0        292620682  Now, one hopes, more attention will be paid to...   \n",
      "1        307490698  His economic program as a candidate in the Rep...   \n",
      "2        307420103  As the Bank of New England hearings suggest, t...   \n",
      "3        307576786  The Justice Department contends that the Eight...   \n",
      "4       1944990599  \"The remittances from drivers alone reach almo...   \n",
      "...            ...                                                ...   \n",
      "493413  2009071770  • A Feb. 28 KidsPost article about an upcoming...   \n",
      "493414  1933811831  The Washington Post is committed to correcting...   \n",
      "493415  2411004924  Kohl's has reopened most of its more than 1,10...   \n",
      "493416  1950787340  Hadges left the DEA in May to join the pharmac...   \n",
      "493417  2321287809  The building does not have carbon monoxide det...   \n",
      "\n",
      "        NounChunksMatch                                NounChunkMatchWords  \\\n",
      "0                     8  [land use, civil right, land use, land use, lo...   \n",
      "1                     2                                 [tax cut, tax cut]   \n",
      "2                    10  [new england, bank hold company, new england, ...   \n",
      "3                     4  [civil action, criminal activity, civil claim,...   \n",
      "4                     1                            [government regulation]   \n",
      "...                 ...                                                ...   \n",
      "493413                1                                     [marine corps]   \n",
      "493414                2  [north american free trade agreement, federal ...   \n",
      "493415                4  [multiple state, public health, health care, p...   \n",
      "493416                3    [one person, high standard, enforcement action]   \n",
      "493417                1                                  [carbon monoxide]   \n",
      "\n",
      "                              NounChunkMatchWordsFiltered  \\\n",
      "0       [land use, civil right, land use, land use, pu...   \n",
      "1                                      [tax cut, tax cut]   \n",
      "2       [bank hold company, real estate, net worth, mu...   \n",
      "3          [civil action, criminal activity, civil claim]   \n",
      "4                                 [government regulation]   \n",
      "...                                                   ...   \n",
      "493413                                     [marine corps]   \n",
      "493414  [north american free trade agreement, federal ...   \n",
      "493415        [public health, health care, public health]   \n",
      "493416                [high standard, enforcement action]   \n",
      "493417                                  [carbon monoxide]   \n",
      "\n",
      "        NounChunkMatchFiltered  \\\n",
      "0                            7   \n",
      "1                            2   \n",
      "2                            4   \n",
      "3                            3   \n",
      "4                            1   \n",
      "...                        ...   \n",
      "493413                       1   \n",
      "493414                       2   \n",
      "493415                       3   \n",
      "493416                       2   \n",
      "493417                       1   \n",
      "\n",
      "                                        DominantNounChunk  \\\n",
      "0                                              [land use]   \n",
      "1                                               [tax cut]   \n",
      "2       [bank hold company, real estate, net worth, mu...   \n",
      "3          [civil action, criminal activity, civil claim]   \n",
      "4                                 [government regulation]   \n",
      "...                                                   ...   \n",
      "493413                                     [marine corps]   \n",
      "493414  [north american free trade agreement, federal ...   \n",
      "493415                                    [public health]   \n",
      "493416                [high standard, enforcement action]   \n",
      "493417                                  [carbon monoxide]   \n",
      "\n",
      "          DominantNounChunkArea                             AllAreas  \\\n",
      "0                           {5}  [5, 14, 15, 16, 5, 5, 2, 11, 15, 3]   \n",
      "1                           {7}                               [7, 7]   \n",
      "2             {2, 7, 8, 10, 15}        [7, 8, 2, 8, 10, 7, 15, 7, 8]   \n",
      "3            {2, 4, 11, 15, 16}               [4, 2, 15, 16, 11, 15]   \n",
      "4                           {7}                                  [7]   \n",
      "...                         ...                                  ...   \n",
      "493413                      {2}                                  [2]   \n",
      "493414  {2, 3, 5, 7, 9, 14, 16}              [2, 3, 7, 9, 14, 16, 5]   \n",
      "493415                  {1, 10}       [1, 10, 1, 4, 7, 8, 15, 1, 10]   \n",
      "493416              {11, 5, 15}                          [11, 5, 15]   \n",
      "493417                      {5}                                  [5]   \n",
      "\n",
      "                                                AreaCount  ...  \\\n",
      "0       [(5, 3), (15, 2), (14, 1), (16, 1), (2, 1), (1...  ...   \n",
      "1                                                [(7, 2)]  ...   \n",
      "2              [(7, 3), (8, 3), (2, 1), (10, 1), (15, 1)]  ...   \n",
      "3             [(15, 2), (4, 1), (2, 1), (16, 1), (11, 1)]  ...   \n",
      "4                                                [(7, 1)]  ...   \n",
      "...                                                   ...  ...   \n",
      "493413                                           [(2, 1)]  ...   \n",
      "493414  [(2, 1), (3, 1), (7, 1), (9, 1), (14, 1), (16,...  ...   \n",
      "493415  [(1, 3), (10, 2), (4, 1), (7, 1), (8, 1), (15,...  ...   \n",
      "493416                         [(11, 1), (5, 1), (15, 1)]  ...   \n",
      "493417                                           [(5, 1)]  ...   \n",
      "\n",
      "       DominantNounChunkArea7 DominantNounChunkArea8 DominantNounChunkArea9  \\\n",
      "0                           0                      0                      0   \n",
      "1                           1                      0                      0   \n",
      "2                           1                      1                      0   \n",
      "3                           0                      0                      0   \n",
      "4                           1                      0                      0   \n",
      "...                       ...                    ...                    ...   \n",
      "493413                      0                      0                      0   \n",
      "493414                      1                      0                      1   \n",
      "493415                      0                      0                      0   \n",
      "493416                      0                      0                      0   \n",
      "493417                      0                      0                      0   \n",
      "\n",
      "       DominantNounChunkArea10 DominantNounChunkArea11  \\\n",
      "0                            0                       0   \n",
      "1                            0                       0   \n",
      "2                            1                       0   \n",
      "3                            0                       1   \n",
      "4                            0                       0   \n",
      "...                        ...                     ...   \n",
      "493413                       0                       0   \n",
      "493414                       0                       0   \n",
      "493415                       1                       0   \n",
      "493416                       0                       1   \n",
      "493417                       0                       0   \n",
      "\n",
      "       DominantNounChunkArea12 DominantNounChunkArea13  \\\n",
      "0                            0                       0   \n",
      "1                            0                       0   \n",
      "2                            0                       0   \n",
      "3                            0                       0   \n",
      "4                            0                       0   \n",
      "...                        ...                     ...   \n",
      "493413                       0                       0   \n",
      "493414                       0                       0   \n",
      "493415                       0                       0   \n",
      "493416                       0                       0   \n",
      "493417                       0                       0   \n",
      "\n",
      "       DominantNounChunkArea14 DominantNounChunkArea15 DominantNounChunkArea16  \n",
      "0                            0                       0                       0  \n",
      "1                            0                       0                       0  \n",
      "2                            0                       1                       0  \n",
      "3                            0                       1                       1  \n",
      "4                            0                       0                       0  \n",
      "...                        ...                     ...                     ...  \n",
      "493413                       0                       0                       0  \n",
      "493414                       1                       0                       1  \n",
      "493415                       0                       0                       0  \n",
      "493416                       0                       1                       0  \n",
      "493417                       0                       0                       0  \n",
      "\n",
      "[493418 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    var='DominantNounChunkArea'+str(i)\n",
    "    df[var]=0\n",
    "    for j in range(0, len(df)):\n",
    "        if i in df['DominantNounChunkArea'][j]:\n",
    "            df[var][j]=1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dummies by dominant area (da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    var='DominantArea'+str(i)\n",
    "    df[var]=0\n",
    "    for j in range(0, len(df)):\n",
    "        if i in df['DominantArea'][j]:\n",
    "            df[var][j]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Dummies by distinct area (uda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    var='UniqueDistinctArea'+str(i)\n",
    "    df[var]=0\n",
    "    for j in range(0, len(df)):\n",
    "        if i in df['UniqueDistinctAreas'][j]:\n",
    "            df[var][j]=1\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Dummies by dominant distinct area (dda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.conda/envs/my_py/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(1,17):\n",
    "    var='DominantDistinctArea'+str(i)\n",
    "    df[var]=0\n",
    "    for j in range(0, len(df)):\n",
    "        if i in df['DominantDistinctArea'][j]:\n",
    "            df[var][j]=1\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                     RegSentsExpand  \\\n",
      "0   292620682  Now, one hopes, more attention will be paid to...   \n",
      "1   307490698  His economic program as a candidate in the Rep...   \n",
      "2   307420103  As the Bank of New England hearings suggest, t...   \n",
      "3   307576786  The Justice Department contends that the Eight...   \n",
      "4  1944990599  \"The remittances from drivers alone reach almo...   \n",
      "\n",
      "   NounChunksMatch                                NounChunkMatchWords  \\\n",
      "0                8  [land use, civil right, land use, land use, lo...   \n",
      "1                2                                 [tax cut, tax cut]   \n",
      "2               10  [new england, bank hold company, new england, ...   \n",
      "3                4  [civil action, criminal activity, civil claim,...   \n",
      "4                1                            [government regulation]   \n",
      "\n",
      "                         NounChunkMatchWordsFiltered  NounChunkMatchFiltered  \\\n",
      "0  [land use, civil right, land use, land use, pu...                       7   \n",
      "1                                 [tax cut, tax cut]                       2   \n",
      "2  [bank hold company, real estate, net worth, mu...                       4   \n",
      "3     [civil action, criminal activity, civil claim]                       3   \n",
      "4                            [government regulation]                       1   \n",
      "\n",
      "                                   DominantNounChunk DominantNounChunkArea  \\\n",
      "0                                         [land use]                   {5}   \n",
      "1                                          [tax cut]                   {7}   \n",
      "2  [bank hold company, real estate, net worth, mu...     {2, 7, 8, 10, 15}   \n",
      "3     [civil action, criminal activity, civil claim]    {2, 4, 11, 15, 16}   \n",
      "4                            [government regulation]                   {7}   \n",
      "\n",
      "                              AllAreas  \\\n",
      "0  [5, 14, 15, 16, 5, 5, 2, 11, 15, 3]   \n",
      "1                               [7, 7]   \n",
      "2        [7, 8, 2, 8, 10, 7, 15, 7, 8]   \n",
      "3               [4, 2, 15, 16, 11, 15]   \n",
      "4                                  [7]   \n",
      "\n",
      "                                           AreaCount  ...  \\\n",
      "0  [(5, 3), (15, 2), (14, 1), (16, 1), (2, 1), (1...  ...   \n",
      "1                                           [(7, 2)]  ...   \n",
      "2         [(7, 3), (8, 3), (2, 1), (10, 1), (15, 1)]  ...   \n",
      "3        [(15, 2), (4, 1), (2, 1), (16, 1), (11, 1)]  ...   \n",
      "4                                           [(7, 1)]  ...   \n",
      "\n",
      "  DominantDistinctArea11 DominantDistinctArea12 DominantDistinctArea13  \\\n",
      "0                      0                      0                      0   \n",
      "1                      0                      0                      0   \n",
      "2                      0                      0                      0   \n",
      "3                      0                      0                      0   \n",
      "4                      0                      0                      0   \n",
      "\n",
      "  DominantDistinctArea14 DominantDistinctArea15 DominantDistinctArea16  \\\n",
      "0                      0                      0                      0   \n",
      "1                      0                      0                      0   \n",
      "2                      0                      0                      0   \n",
      "3                      0                      0                      0   \n",
      "4                      0                      0                      0   \n",
      "\n",
      "  DominantNounChunkArea8-9 DominantArea8-9 UniqueDistinctArea8-9  \\\n",
      "0                        0               0                     0   \n",
      "1                        0               0                     0   \n",
      "2                        1               1                     0   \n",
      "3                        0               0                     0   \n",
      "4                        0               0                     0   \n",
      "\n",
      "  DominantDistinctArea8-9  \n",
      "0                       0  \n",
      "1                       0  \n",
      "2                       0  \n",
      "3                       0  \n",
      "4                       0  \n",
      "\n",
      "[5 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine areas 8 & 9\n",
    "for var in ['DominantNounChunkArea','DominantArea','UniqueDistinctArea','DominantDistinctArea']:\n",
    "    df[var+'8-9']=0\n",
    "    df.loc[(df[var+'8']==1) | (df[var+'9']==1), var+'8-9']=1\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Monthly article counts by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2945 entries, 0 to 2944\n",
      "Data columns (total 71 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Newspaper                 2945 non-null   object\n",
      " 1   Year                      2945 non-null   int64 \n",
      " 2   Month                     2945 non-null   int64 \n",
      " 3   DominantNounChunkArea1    2945 non-null   int64 \n",
      " 4   DominantArea1             2945 non-null   int64 \n",
      " 5   UniqueDistinctArea1       2945 non-null   int64 \n",
      " 6   DominantDistinctArea1     2945 non-null   int64 \n",
      " 7   DominantNounChunkArea2    2945 non-null   int64 \n",
      " 8   DominantArea2             2945 non-null   int64 \n",
      " 9   UniqueDistinctArea2       2945 non-null   int64 \n",
      " 10  DominantDistinctArea2     2945 non-null   int64 \n",
      " 11  DominantNounChunkArea3    2945 non-null   int64 \n",
      " 12  DominantArea3             2945 non-null   int64 \n",
      " 13  UniqueDistinctArea3       2945 non-null   int64 \n",
      " 14  DominantDistinctArea3     2945 non-null   int64 \n",
      " 15  DominantNounChunkArea4    2945 non-null   int64 \n",
      " 16  DominantArea4             2945 non-null   int64 \n",
      " 17  UniqueDistinctArea4       2945 non-null   int64 \n",
      " 18  DominantDistinctArea4     2945 non-null   int64 \n",
      " 19  DominantNounChunkArea5    2945 non-null   int64 \n",
      " 20  DominantArea5             2945 non-null   int64 \n",
      " 21  UniqueDistinctArea5       2945 non-null   int64 \n",
      " 22  DominantDistinctArea5     2945 non-null   int64 \n",
      " 23  DominantNounChunkArea6    2945 non-null   int64 \n",
      " 24  DominantArea6             2945 non-null   int64 \n",
      " 25  UniqueDistinctArea6       2945 non-null   int64 \n",
      " 26  DominantDistinctArea6     2945 non-null   int64 \n",
      " 27  DominantNounChunkArea7    2945 non-null   int64 \n",
      " 28  DominantArea7             2945 non-null   int64 \n",
      " 29  UniqueDistinctArea7       2945 non-null   int64 \n",
      " 30  DominantDistinctArea7     2945 non-null   int64 \n",
      " 31  DominantNounChunkArea8    2945 non-null   int64 \n",
      " 32  DominantArea8             2945 non-null   int64 \n",
      " 33  UniqueDistinctArea8       2945 non-null   int64 \n",
      " 34  DominantDistinctArea8     2945 non-null   int64 \n",
      " 35  DominantNounChunkArea9    2945 non-null   int64 \n",
      " 36  DominantArea9             2945 non-null   int64 \n",
      " 37  UniqueDistinctArea9       2945 non-null   int64 \n",
      " 38  DominantDistinctArea9     2945 non-null   int64 \n",
      " 39  DominantNounChunkArea10   2945 non-null   int64 \n",
      " 40  DominantArea10            2945 non-null   int64 \n",
      " 41  UniqueDistinctArea10      2945 non-null   int64 \n",
      " 42  DominantDistinctArea10    2945 non-null   int64 \n",
      " 43  DominantNounChunkArea11   2945 non-null   int64 \n",
      " 44  DominantArea11            2945 non-null   int64 \n",
      " 45  UniqueDistinctArea11      2945 non-null   int64 \n",
      " 46  DominantDistinctArea11    2945 non-null   int64 \n",
      " 47  DominantNounChunkArea12   2945 non-null   int64 \n",
      " 48  DominantArea12            2945 non-null   int64 \n",
      " 49  UniqueDistinctArea12      2945 non-null   int64 \n",
      " 50  DominantDistinctArea12    2945 non-null   int64 \n",
      " 51  DominantNounChunkArea13   2945 non-null   int64 \n",
      " 52  DominantArea13            2945 non-null   int64 \n",
      " 53  UniqueDistinctArea13      2945 non-null   int64 \n",
      " 54  DominantDistinctArea13    2945 non-null   int64 \n",
      " 55  DominantNounChunkArea14   2945 non-null   int64 \n",
      " 56  DominantArea14            2945 non-null   int64 \n",
      " 57  UniqueDistinctArea14      2945 non-null   int64 \n",
      " 58  DominantDistinctArea14    2945 non-null   int64 \n",
      " 59  DominantNounChunkArea15   2945 non-null   int64 \n",
      " 60  DominantArea15            2945 non-null   int64 \n",
      " 61  UniqueDistinctArea15      2945 non-null   int64 \n",
      " 62  DominantDistinctArea15    2945 non-null   int64 \n",
      " 63  DominantNounChunkArea16   2945 non-null   int64 \n",
      " 64  DominantArea16            2945 non-null   int64 \n",
      " 65  UniqueDistinctArea16      2945 non-null   int64 \n",
      " 66  DominantDistinctArea16    2945 non-null   int64 \n",
      " 67  DominantNounChunkArea8-9  2945 non-null   int64 \n",
      " 68  DominantArea8-9           2945 non-null   int64 \n",
      " 69  UniqueDistinctArea8-9     2945 non-null   int64 \n",
      " 70  DominantDistinctArea8-9   2945 non-null   int64 \n",
      "dtypes: int64(70), object(1)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Aggregate monthly article counts\n",
    "monthlyAreaCount=df[['Newspaper','Year','Month']+col_list].groupby(['Newspaper','Year','Month']).agg('sum').reset_index()\n",
    "print(monthlyAreaCount.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Newspaper  Year  Month  DominantNounChunkArea1  DominantArea1  \\\n",
      "0  Boston Globe  1985      1                      21             13   \n",
      "1  Boston Globe  1985      2                      29             24   \n",
      "2  Boston Globe  1985      3                      34             21   \n",
      "3  Boston Globe  1985      4                      32             23   \n",
      "4  Boston Globe  1985      5                      37             25   \n",
      "\n",
      "   UniqueDistinctArea1  DominantDistinctArea1  DominantNounChunkArea2  \\\n",
      "0                   13                      7                      21   \n",
      "1                   12                     12                      27   \n",
      "2                   15                     12                      29   \n",
      "3                   12                      9                      33   \n",
      "4                   15                     14                      32   \n",
      "\n",
      "   DominantArea2  UniqueDistinctArea2  ...  UniqueDistinctArea15  \\\n",
      "0             15                   13  ...                     4   \n",
      "1             17                    6  ...                     6   \n",
      "2             15                   10  ...                     6   \n",
      "3             21                   10  ...                     4   \n",
      "4             15                    6  ...                    10   \n",
      "\n",
      "   DominantDistinctArea15  DominantNounChunkArea16  DominantArea16  \\\n",
      "0                       3                        7               2   \n",
      "1                       5                       15               7   \n",
      "2                       5                       14               4   \n",
      "3                       4                       14               7   \n",
      "4                       8                       14               9   \n",
      "\n",
      "   UniqueDistinctArea16  DominantDistinctArea16  DominantNounChunkArea8-9  \\\n",
      "0                     1                       0                        18   \n",
      "1                     0                       0                        26   \n",
      "2                     0                       0                        22   \n",
      "3                     0                       0                        24   \n",
      "4                     2                       1                        27   \n",
      "\n",
      "   DominantArea8-9  UniqueDistinctArea8-9  DominantDistinctArea8-9  \n",
      "0               13                     11                       10  \n",
      "1               15                     13                       10  \n",
      "2               12                     13                       11  \n",
      "3               12                     10                        9  \n",
      "4               12                      9                        9  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "print(monthlyAreaCount.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyAreaCount.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_MonthlyArticleCountByNewspaper.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge with sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 493418 entries, 0 to 493417\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ID                493418 non-null  int64  \n",
      " 1   StartDate         493418 non-null  object \n",
      " 2   Newspaper         493418 non-null  object \n",
      " 3   UncertaintyScore  493418 non-null  float64\n",
      " 4   GIscore           493418 non-null  float64\n",
      " 5   LMscore           493418 non-null  float64\n",
      " 6   LSDscore          493418 non-null  float64\n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 26.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Merge with sentiment scores\n",
    "sentimentScores=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/RegRelevant_ArticleSentimentScores.csv')\n",
    "print(sentimentScores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "df['ID']=df['ID'].astype('int64')\n",
    "df2=df.merge(sentimentScores[['ID','UncertaintyScore','GIscore','LMscore','LSDscore']],on='ID',how='left')\n",
    "#print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['ID','StartDate','Newspaper','UncertaintyScore','GIscore','LMscore','LSDscore']+col_list].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_ArticleSentimentScores.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 428 entries, 0 to 427\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   Year          428 non-null    int64\n",
      " 1   Month         428 non-null    int64\n",
      " 2   ArticleCount  428 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 10.2 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Calculate average monthly scores by area\n",
    "df_reg=df2\n",
    "df_reg['ArticleCount']=1\n",
    "monthlyAreaScores=df_reg[['Year','Month','ArticleCount']].\\\n",
    "    groupby(['Year','Month']).agg({'ArticleCount':'sum'}).reset_index()\n",
    "print(monthlyAreaScores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 428 entries, 0 to 427\n",
      "Columns: 343 entries, Year to ArticleCount_DominantDistinctArea8-9\n",
      "dtypes: float64(276), int64(67)\n",
      "memory usage: 1.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for var in col_list:\n",
    "    df_area=df_reg[df_reg[var]==1].reset_index(drop=True)\n",
    "    areaScore=df_area[['Year','Month','UncertaintyScore','GIscore','LSDscore','LMscore','ArticleCount']].\\\n",
    "                                    groupby(['Year','Month']).agg({'UncertaintyScore':'mean','GIscore':'mean',\n",
    "                                   'LSDscore':'mean','LMscore':'mean','ArticleCount':'sum'}).reset_index()\n",
    "    areaScore=areaScore.rename(columns={'UncertaintyScore':'UncertaintyScore'+'_'+var,'GIscore':'GIscore'+'_'+var,\n",
    "                                       'LSDscore':'LSDscore'+'_'+var,'LMscore':'LMscore'+'_'+var,'ArticleCount':'ArticleCount'+'_'+var})\n",
    "    monthlyAreaScores=monthlyAreaScores.merge(areaScore,on=['Year','Month'],how='left')\n",
    "print(monthlyAreaScores.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyAreaScores.to_csv('/home/ec2-user/SageMaker/New Uncertainty/Categorical Index/RegArea_MonthlySentimentScores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1. Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the results\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most negative/positive articles in specified area\n",
    "temp=df2[(df2['DominantDistinctArea3']==1) & (df2['Year']==2014) & (df2['Month']==10)]\n",
    "temp=temp.sort_values('LMscore').reset_index(drop=True)\n",
    "print(temp[['ID','LMscore']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(temp)):\n",
    "    print(temp['ID'][i],temp['Title'][i],':',temp['Newspaper'][i],'\\n',temp['RegSentsExpand'][i],temp['NounChunkMatchWordsFiltered'][i],\n",
    "          temp['AllDistinctAreas'][i], temp['DominantDistinctArea'][i],temp['LMscore'][i],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(df)):\n",
    "    if  (df['Year'][i]==2002) & (df['Month'][i]==7):\n",
    "        print(df['ID'][i],df['Title'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
