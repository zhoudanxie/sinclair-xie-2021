{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import time\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9278 entries, 0 to 9277\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   ID                           9278 non-null   object        \n",
      " 1   Title                        9278 non-null   object        \n",
      " 2   Type                         9278 non-null   object        \n",
      " 3   StartDate                    9278 non-null   datetime64[ns]\n",
      " 4   EndDate                      9278 non-null   object        \n",
      " 5   Text                         9278 non-null   object        \n",
      " 6   TextWordCount                9278 non-null   object        \n",
      " 7   PubTitle                     9278 non-null   object        \n",
      " 8   SourceType                   9278 non-null   object        \n",
      " 9   Year                         9278 non-null   int64         \n",
      " 10  Month                        9278 non-null   int64         \n",
      " 11  Newspaper                    9278 non-null   object        \n",
      " 12  RegSentsExpand               9278 non-null   object        \n",
      " 13  RegSentExpandLen             9278 non-null   int64         \n",
      " 14  NounChunkMatchFiltered       9278 non-null   int64         \n",
      " 15  NounChunkMatchWordsFiltered  9278 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(11)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Import expanded reg sentences\n",
    "df_regSentsExpand=pd.read_pickle('/home/ec2-user/SageMaker/New Uncertainty/Update Data/RegSentsExpand_NounChunks_Update.pkl')\n",
    "print(df_regSentsExpand.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5832 entries, 0 to 5831\n",
      "Data columns (total 16 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   ID                           5832 non-null   object        \n",
      " 1   Title                        5832 non-null   object        \n",
      " 2   Type                         5832 non-null   object        \n",
      " 3   StartDate                    5832 non-null   datetime64[ns]\n",
      " 4   EndDate                      5832 non-null   object        \n",
      " 5   Text                         5832 non-null   object        \n",
      " 6   TextWordCount                5832 non-null   object        \n",
      " 7   PubTitle                     5832 non-null   object        \n",
      " 8   SourceType                   5832 non-null   object        \n",
      " 9   Year                         5832 non-null   int64         \n",
      " 10  Month                        5832 non-null   int64         \n",
      " 11  Newspaper                    5832 non-null   object        \n",
      " 12  RegSentsExpand               5832 non-null   object        \n",
      " 13  RegSentExpandLen             5832 non-null   int64         \n",
      " 14  NounChunkMatchFiltered       5832 non-null   int64         \n",
      " 15  NounChunkMatchWordsFiltered  5832 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(11)\n",
      "memory usage: 729.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Refine to reg relevant articles\n",
    "df=df_regSentsExpand[df_regSentsExpand['NounChunkMatchFiltered']>0].reset_index(drop=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negation words\n",
    "negate = [\"aint\", \"arent\", \"cannot\", \"cant\", \"couldnt\", \"darent\", \"didnt\", \"doesnt\", \"ain't\", \"aren't\", \"can't\",\n",
    "          \"couldn't\", \"daren't\", \"didn't\", \"doesn't\", \"dont\", \"hadnt\", \"hasnt\", \"havent\", \"isnt\", \"mightnt\", \"mustnt\",\n",
    "          \"neither\", \"don't\", \"hadn't\", \"hasn't\", \"haven't\", \"isn't\", \"mightn't\", \"mustn't\", \"neednt\", \"needn't\",\n",
    "          \"never\", \"none\", \"nope\", \"nor\", \"not\", \"nothing\", \"nowhere\", \"oughtnt\", \"shant\", \"shouldnt\", \"wasnt\",\n",
    "          \"werent\", \"oughtn't\", \"shan't\", \"shouldn't\", \"wasn't\", \"weren't\", \"without\", \"wont\", \"wouldnt\", \"won't\",\n",
    "          \"wouldn't\", \"rarely\", \"seldom\", \"despite\", \"no\", \"nobody\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to negate\n",
    "def negated(word):\n",
    "    # Determine if preceding word is a negation word\n",
    "    if word.lower() in negate:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize\n",
    "def tokenizer(text):\n",
    "    doc=nlp(text)\n",
    "    tokens=[token.text.lower() for token in doc if not token.is_punct | token.is_space]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lemmatize\n",
    "def lemmatizer(text):\n",
    "    doc=nlp(text)\n",
    "    lemmas=[token.lemma_ for token in doc if not token.is_punct | token.is_space]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2355 entries, 0 to 2354\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Negative     2355 non-null   object\n",
      " 1   Positive     354 non-null    object\n",
      " 2   Uncertainty  297 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 55.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# LM dictionary\n",
    "LMlist=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LoughranMcDonald_SentimentList.csv')\n",
    "print(LMlist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LM uncertainty dictionary\n",
    "LMuncertain=LMlist[LMlist['Uncertainty'].notnull()]['Uncertainty'].tolist()\n",
    "uncertaindict={'Uncertainty': [w.lower() for w in LMuncertain]}\n",
    "#print(uncertaindict, len(LMuncertain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize LM uncertainty dictionary\n",
    "uncertainset=set()\n",
    "for w in uncertaindict['Uncertainty']:\n",
    "    v=''.join(lemmatizer(w))\n",
    "    uncertainset.add(v)\n",
    "uncertainlist_lemmatized=list(uncertainset)\n",
    "print(len(uncertainlist_lemmatized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arbitrary', 'random', 'unspecified', 'possible', 'unreconciled', 'approximated', 'conditional', 'predictability', 'randomized', 'seldomly', 'reassesse', 'unpredictable', 'pende', 'risk', 'unclear', 'undeterminable', 'cautiousness', 'unforecasted', 'inexact', 'speculate']\n"
     ]
    }
   ],
   "source": [
    "print(uncertainlist_lemmatized[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count uncertainty terms\n",
    "def uncertainty_count(keywords_list, article):\n",
    "\n",
    "    uncertain_count = 0\n",
    "    uncertain_words = []\n",
    " \n",
    "    input_words=lemmatizer(article)\n",
    "    word_count = len(input_words)\n",
    "    \n",
    "    for i in range(0, word_count):\n",
    "        if input_words[i] in keywords_list:\n",
    "            uncertain_count += 1\n",
    "            uncertain_words.append(input_words[i])\n",
    "    \n",
    "    results = [uncertain_count, uncertain_words]\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5832\n"
     ]
    }
   ],
   "source": [
    "# Run LM uncertainty through all expanded reg sentences\n",
    "UncertaintyCount=[]\n",
    "UncertaintyWords=[]\n",
    "for text in df['RegSentsExpand']:\n",
    "    results=uncertainty_count(uncertainlist_lemmatized, text)\n",
    "    UncertaintyCount.append(results[0])\n",
    "    UncertaintyWords.append(results[1])\n",
    "print(len(UncertaintyCount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5832 entries, 0 to 5831\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   ID                           5832 non-null   object        \n",
      " 1   Title                        5832 non-null   object        \n",
      " 2   Type                         5832 non-null   object        \n",
      " 3   StartDate                    5832 non-null   datetime64[ns]\n",
      " 4   EndDate                      5832 non-null   object        \n",
      " 5   Text                         5832 non-null   object        \n",
      " 6   TextWordCount                5832 non-null   object        \n",
      " 7   PubTitle                     5832 non-null   object        \n",
      " 8   SourceType                   5832 non-null   object        \n",
      " 9   Year                         5832 non-null   int64         \n",
      " 10  Month                        5832 non-null   int64         \n",
      " 11  Newspaper                    5832 non-null   object        \n",
      " 12  RegSentsExpand               5832 non-null   object        \n",
      " 13  RegSentExpandLen             5832 non-null   int64         \n",
      " 14  NounChunkMatchFiltered       5832 non-null   int64         \n",
      " 15  NounChunkMatchWordsFiltered  5832 non-null   object        \n",
      " 16  UncertaintyCount             5832 non-null   int64         \n",
      " 17  UncertaintyWords             5832 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(5), object(12)\n",
      "memory usage: 820.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df['UncertaintyCount']=UncertaintyCount\n",
    "df['UncertaintyWords']=UncertaintyWords\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3251\n"
     ]
    }
   ],
   "source": [
    "print(df[df['UncertaintyCount']!=0]['ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  UncertaintyCount UncertaintyWords\n",
      "0  2439045441                 0               []\n",
      "1  2439087004                 0               []\n",
      "2  2439148856                 0               []\n",
      "3  2439148786                 0               []\n",
      "4  2439451714                 2     [could, may]\n",
      "5  2439499322                 2       [may, may]\n",
      "6  2439513636                 2       [may, may]\n",
      "7  2439548917                 2       [may, may]\n",
      "8  2439548934                 2     [may, could]\n",
      "9  2439794438                 0               []\n"
     ]
    }
   ],
   "source": [
    "print(df[['ID','UncertaintyCount','UncertaintyWords']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','UncertaintyCount','UncertaintyWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Update Data/LMuncertainty_Update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count sentiment terms\n",
    "def sentiment_count(dict, article):\n",
    "    \"\"\"\n",
    "    Count positive and negative words with negation check. Account for simple negation only for positive words.\n",
    "    Simple negation is taken to be observations of one of negate words occurring within three words\n",
    "    preceding a positive words.\n",
    "    \"\"\"\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    " \n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    " \n",
    "    input_words=lemmatizer(article)\n",
    " \n",
    "    word_count = len(input_words)\n",
    " \n",
    "    for i in range(0, word_count):\n",
    "        if input_words[i] in dict['Negative']:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                neg_count += 1\n",
    "                neg_words.append(input_words[i])\n",
    "            \n",
    "        if input_words[i] in dict['Positive']:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                pos_count += 1\n",
    "                pos_words.append(input_words[i])\n",
    "    '''\n",
    "    print('The results with negation check:', end='\\n\\n')\n",
    "    print('The # of positive words:', pos_count)\n",
    "    print('The # of negative words:', neg_count)\n",
    "    print('The list of found positive words:', pos_words)\n",
    "    print('The list of found negative words:', neg_words)\n",
    "    print('\\n', end='')\n",
    "    '''\n",
    "    \n",
    "    results = [word_count, pos_count, neg_count, pos_words, neg_words]\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2355 354\n",
      "['ABANDON', 'ABANDONED', 'ABANDONING', 'ABANDONMENT', 'ABANDONMENTS', 'ABANDONS', 'ABDICATED', 'ABDICATES', 'ABDICATING', 'ABDICATION', 'ABDICATIONS', 'ABERRANT', 'ABERRATION', 'ABERRATIONAL', 'ABERRATIONS', 'ABETTING', 'ABNORMAL', 'ABNORMALITIES', 'ABNORMALITY', 'ABNORMALLY'] ['ABLE', 'ABUNDANCE', 'ABUNDANT', 'ACCLAIMED', 'ACCOMPLISH', 'ACCOMPLISHED', 'ACCOMPLISHES', 'ACCOMPLISHING', 'ACCOMPLISHMENT', 'ACCOMPLISHMENTS', 'ACHIEVE', 'ACHIEVED', 'ACHIEVEMENT', 'ACHIEVEMENTS', 'ACHIEVES', 'ACHIEVING', 'ADEQUATELY', 'ADVANCEMENT', 'ADVANCEMENTS', 'ADVANCES']\n"
     ]
    }
   ],
   "source": [
    "# LM sentiment dictionary\n",
    "LMposWords=LMlist[LMlist['Positive'].notnull()]['Positive'].tolist()\n",
    "LMnegWords=LMlist[LMlist['Negative'].notnull()]['Negative'].tolist()\n",
    "print(len(LMnegWords),len(LMposWords))\n",
    "print(LMnegWords[0:20],LMposWords[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "# Lemmatize LM sentiment dictionary\n",
    "LMnegset=set()\n",
    "for w in LMnegWords:\n",
    "    v=''.join(lemmatizer(w.lower()))\n",
    "    LMnegset.add(v)\n",
    "print(len(LMnegset))\n",
    "\n",
    "LMposset=set()\n",
    "for w in LMposWords:\n",
    "    v=''.join(lemmatizer(w.lower()))\n",
    "    LMposset.add(v)\n",
    "print(len(LMposset))\n",
    "\n",
    "LMdict={'Negative': list(LMnegset), 'Positive': list(LMposset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['transparency', 'enable', 'great', 'honors', 'delightfully', 'lucrative', 'proficient', 'strength', 'advance', 'distinctive', 'pleased', 'premier', 'happiness', 'acclaim', 'enhance', 'gain', 'impressive', 'satisfactory', 'superior', 'encourages']\n",
      "['gratuitous', 'drastically', 'recall', 'abrupt', 'noncompliance', 'incapacity', 'distorted', 'misdemeanor', 'jeopardized', 'unattractive', 'inconvenience', 'indict', 'mislabeled', 'collusion', 'sluggishness', 'ignore', 'disadvantaged', 'disparagements', 'cybercrimes', 'denigration']\n"
     ]
    }
   ],
   "source": [
    "print(LMdict['Positive'][0:20])\n",
    "print(LMdict['Negative'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LM sentiment through all expanded reg sentences\n",
    "LMpositiveCount=[]\n",
    "LMnegativeCount=[]\n",
    "LMpositiveWords=[]\n",
    "LMnegativeWords=[]\n",
    "for text in df['RegSentsExpand']:\n",
    "    results=sentiment_count(LMdict, text)\n",
    "    LMpositiveCount.append(results[1])\n",
    "    LMnegativeCount.append(results[2])\n",
    "    LMpositiveWords.append(results[3])\n",
    "    LMnegativeWords.append(results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LMposCount']=LMpositiveCount\n",
    "df['LMnegCount']=LMnegativeCount\n",
    "df['LMposWords']=LMpositiveWords\n",
    "df['LMnegWords']=LMnegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','LMposCount','LMnegCount','LMposWords','LMnegWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Update Data/LMsentiments_Update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harvard GI sentiment dictionary\n",
    "with open(\"/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/GIposWords.txt\", \"rb\") as fp:   # Unpickling\n",
    "    GIposWords = pickle.load(fp)\n",
    "with open(\"/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/GInegWords.txt\", \"rb\") as fp:   # Unpickling\n",
    "    GInegWords = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637 ['ABIDE', 'ABILITY', 'ABLE', 'ABOUND', 'ABSOLVE', 'ABSORBENT', 'ABSORPTION', 'ABUNDANCE', 'ABUNDANT', 'ACCEDE', 'ACCENTUATE', 'ACCEPT', 'ACCEPTABLE', 'ACCEPTANCE', 'ACCESSIBLE', 'ACCESSION', 'ACCLAIM', 'ACCLAMATION', 'ACCOLADE', 'ACCOMMODATE']\n",
      "2005 ['ABANDON', 'ABANDONMENT', 'ABATE', 'ABDICATE', 'ABHOR', 'ABJECT', 'ABNORMAL', 'ABOLISH', 'ABOMINABLE', 'ABRASIVE', 'ABRUPT', 'ABSCOND', 'ABSENCE', 'ABSENT', 'ABSENT-MINDED', 'ABSENTEE', 'ABSURD', 'ABSURDITY', 'ABUSE', 'ABYSS']\n"
     ]
    }
   ],
   "source": [
    "print(len(GIposWords),GIposWords[0:20])\n",
    "print(len(GInegWords),GInegWords[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: ['abide', 'ability', 'able', 'abound', 'absolve', 'absorbent', 'absorption', 'abundance', 'abundant', 'accede', 'accentuate', 'accept', 'acceptable', 'acceptance', 'accessible', 'accession', 'acclaim', 'acclamation', 'accolade', 'accommodate']\n",
      "Negative: ['abandon', 'abandonment', 'abate', 'abdicate', 'abhor', 'abject', 'abnormal', 'abolish', 'abominable', 'abrasive', 'abrupt', 'abscond', 'absence', 'absent', 'absent-minded', 'absentee', 'absurd', 'absurdity', 'abuse', 'abyss']\n"
     ]
    }
   ],
   "source": [
    "# Non-lemmetized version of GI dictionary\n",
    "GIdict2={'Negative': [w.lower() for w in GInegWords], 'Positive': [w.lower() for w in GIposWords]}\n",
    "print('Positive:',GIdict2['Positive'][0:20])\n",
    "print('Negative:',GIdict2['Negative'][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run GI sentiment through all expanded reg sentences using non-lemmatized GI dictionary (performs better than lemmatized GI)\n",
    "totalWordCount=[]\n",
    "GIpositiveCount=[]\n",
    "GInegativeCount=[]\n",
    "GIpositiveWords=[]\n",
    "GInegativeWords=[]\n",
    "for text in df['RegSentsExpand']:\n",
    "    results=sentiment_count(GIdict2, text)\n",
    "    totalWordCount.append(results[0])\n",
    "    GIpositiveCount.append(results[1])\n",
    "    GInegativeCount.append(results[2])\n",
    "    GIpositiveWords.append(results[3])\n",
    "    GInegativeWords.append(results[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalWordCount']=totalWordCount\n",
    "df['GIposCount']=GIpositiveCount\n",
    "df['GInegCount']=GInegativeCount\n",
    "df['GIposWords']=GIpositiveWords\n",
    "df['GInegWords']=GInegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','TotalWordCount','GIposCount','GInegCount','GIposWords','GInegWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Update Data/GIsentiments_Update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2858 entries, 0 to 2857\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   LSDnegative  2857 non-null   object\n",
      " 1   LSDpositive  1709 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Lexicoder Sentiment Dictionary (LSD)\n",
    "LSDlist=pd.read_csv('/home/ec2-user/SageMaker/New Uncertainty/Sentiment Analysis/LSDsentimentWords_wStar.csv')\n",
    "print(LSDlist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSDneg=LSDlist[LSDlist['LSDnegative'].notnull()]['LSDnegative'].tolist()\n",
    "LSDpos=LSDlist[LSDlist['LSDpositive'].notnull()]['LSDpositive'].tolist()\n",
    "LSDdict={'Negative': [w.lower() for w in LSDneg], 'Positive': [w.lower() for w in LSDpos]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1082 627\n",
      "2018 839\n"
     ]
    }
   ],
   "source": [
    "# Seperate terms with & without stars in LSD dictionary\n",
    "pos_star=[]\n",
    "pos_nostar=[]\n",
    "for m in LSDdict['Positive']:\n",
    "    if \"*\" in m:\n",
    "        m=m.replace('*','')\n",
    "        pos_star.append(m)\n",
    "    else:\n",
    "        pos_nostar.append(m)\n",
    "print(len(pos_star), len(pos_nostar))\n",
    "\n",
    "neg_star=[]\n",
    "neg_nostar=[]\n",
    "for m in LSDdict['Negative']:\n",
    "    if \"*\" in m:\n",
    "        m=m.replace('*','')\n",
    "        neg_star.append(m)\n",
    "    else:\n",
    "        neg_nostar.append(m)\n",
    "print(len(neg_star), len(neg_nostar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile re patterns for terms with & without stars\n",
    "pattern_pos_nostar=re.compile(r'\\b(?:%s)\\b' % '|'.join(pos_nostar))\n",
    "pattern_pos_star=re.compile(r'\\b(?:%s)[a-zA-Z]*\\b' % '|'.join(pos_star))\n",
    "pattern_neg_nostar=re.compile(r'\\b(?:%s)\\b' % '|'.join(neg_nostar))\n",
    "pattern_neg_star=re.compile(r'\\b(?:%s)[a-zA-Z]*\\b' % '|'.join(neg_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count LSD sentiment terms\n",
    "def LSDsentiment_count(dict, article):\n",
    "    \"\"\"\n",
    "    Count positive and negative words with negation check. Account for simple negation only for positive words.\n",
    "    Simple negation is taken to be observations of one of negate words occurring within three words\n",
    "    preceding a positive words.\n",
    "    \"\"\"\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    " \n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    " \n",
    "    input_words=tokenizer(article)    # No lemmatizing since LSD dictionary includes variations\n",
    " \n",
    "    word_count = len(input_words)\n",
    " \n",
    "    for i in range(0, word_count):\n",
    "        find_neg=pattern_neg_nostar.findall(input_words[i])+pattern_neg_star.findall(input_words[i])\n",
    "        if len(find_neg)>0:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                neg_count += 1\n",
    "                neg_words.append(input_words[i])\n",
    "        \n",
    "        find_pos=pattern_pos_nostar.findall(input_words[i])+pattern_pos_star.findall(input_words[i])\n",
    "        if len(find_pos)>0:\n",
    "            if i >= 3:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]) or negated(input_words[i - 3]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 2:\n",
    "                if negated(input_words[i - 1]) or negated(input_words[i - 2]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 1:\n",
    "                if negated(input_words[i - 1]):\n",
    "                    neg_count += 1\n",
    "                    neg_words.append(input_words[i] + ' (with negation)')\n",
    "                else:\n",
    "                    pos_count += 1\n",
    "                    pos_words.append(input_words[i])\n",
    "            elif i == 0:\n",
    "                pos_count += 1\n",
    "                pos_words.append(input_words[i])\n",
    "    '''\n",
    "    print('The results with negation check:', end='\\n\\n')\n",
    "    print('The # of positive words:', pos_count)\n",
    "    print('The # of negative words:', neg_count)\n",
    "    print('The list of found positive words:', pos_words)\n",
    "    print('The list of found negative words:', neg_words)\n",
    "    print('\\n', end='')\n",
    "    '''\n",
    "    \n",
    "    results = [word_count, pos_count, neg_count, pos_words, neg_words]\n",
    " \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "--- 63.920268535614014 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Run LSD sentiment through all expanded reg sentences\n",
    "start_time = time.time()\n",
    "\n",
    "LSDpositiveCount=[]\n",
    "LSDnegativeCount=[]\n",
    "LSDpositiveWords=[]\n",
    "LSDnegativeWords=[]\n",
    "failed=[]\n",
    "for i in range(0, len(df['RegSentsExpand'])):\n",
    "    try:\n",
    "        results=LSDsentiment_count(LSDdict, df['RegSentsExpand'][i])\n",
    "    except:\n",
    "        results=[None, None, None, None, None]\n",
    "        failed.append(i)        \n",
    "        \n",
    "    LSDpositiveCount.append(results[1])\n",
    "    LSDnegativeCount.append(results[2])\n",
    "    LSDpositiveWords.append(results[3])\n",
    "    LSDnegativeWords.append(results[4])\n",
    "print(len(failed))\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5832\n"
     ]
    }
   ],
   "source": [
    "print(len(failed))\n",
    "print(len(LSDpositiveWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LSDposCount']=LSDpositiveCount\n",
    "df['LSDnegCount']=LSDnegativeCount\n",
    "df['LSDposWords']=LSDpositiveWords\n",
    "df['LSDnegWords']=LSDnegativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID                                              Title  Type  \\\n",
      "0  2439045441        NOAA to boaters: Watch out for right whales  News   \n",
      "1  2439087004  Union's billboards depict the plight of home c...  News   \n",
      "2  2439148856        Boaters urged to watch out for right whales  News   \n",
      "3  2439148786                     Fighting to be seen, and heard  News   \n",
      "4  2439451714  State halts admissions to Mission Hill assiste...  News   \n",
      "\n",
      "   StartDate     EndDate                                               Text  \\\n",
      "0 2020-09-01  2020-09-01  Federal fisheries regulators are asking marine...   \n",
      "1 2020-09-01  2020-09-01  Throughout the pandemic, the 100,000 home care...   \n",
      "2 2020-09-02  2020-09-02  Federal fisheries regulators are asking marine...   \n",
      "3 2020-09-02  2020-09-02  Throughout the pandemic, the 100,000 home care...   \n",
      "4 2020-09-02  2020-09-02  State officials have suspended the certificati...   \n",
      "\n",
      "  TextWordCount               PubTitle  SourceType  Year  ...  \\\n",
      "0           233  Boston Globe (Online)  Newspapers  2020  ...   \n",
      "1           881  Boston Globe (Online)  Newspapers  2020  ...   \n",
      "2           240           Boston Globe  Newspapers  2020  ...   \n",
      "3           824           Boston Globe  Newspapers  2020  ...   \n",
      "4           795  Boston Globe (Online)  Newspapers  2020  ...   \n",
      "\n",
      "                                          LMnegWords TotalWordCount  \\\n",
      "0                                   [slow, endanger]             60   \n",
      "1                                  [hazard, against]            124   \n",
      "2                                   [slow, endanger]             60   \n",
      "3                                  [hazard, against]            124   \n",
      "4  [concern, concern, failure, threat, forbid, co...            260   \n",
      "\n",
      "  GIposCount  GInegCount                                         GIposWords  \\\n",
      "0          5           2    [establish, dynamic, aggregation, right, right]   \n",
      "1         18           9  [home, health, independent, hand, pay, protect...   \n",
      "2          5           2    [establish, dynamic, aggregation, right, right]   \n",
      "3         18           9  [home, health, independent, hand, pay, protect...   \n",
      "4         19          22  [share, offer, protect, health, safety, welfar...   \n",
      "\n",
      "                                          GInegWords  LSDposCount LSDnegCount  \\\n",
      "0                                   [spot, endanger]            2           1   \n",
      "1  [hand, oversight, low, hazard, fight, against,...            7           7   \n",
      "2                                   [spot, endanger]            2           1   \n",
      "3  [hand, oversight, low, hazard, fight, against,...            7           7   \n",
      "4  [concern, concern, service, service, return (w...           11          11   \n",
      "\n",
      "                                         LSDposWords  \\\n",
      "0                                     [right, right]   \n",
      "1  [protective, grace, care, better, care, united...   \n",
      "2                                     [right, right]   \n",
      "3  [protective, grace, care, better, care, united...   \n",
      "4  [protect, comply, safety, corrective, providin...   \n",
      "\n",
      "                                         LSDnegWords  \n",
      "0                                       [endangered]  \n",
      "1  [oversight, hazard, fight, against, racism, fi...  \n",
      "2                                       [endangered]  \n",
      "3  [oversight, hazard, fight, against, racism, fi...  \n",
      "4  [failure, threat, forbidden, emergency, compla...  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The National Oceanic and Atmospheric Administration said it established a “dynamic management area” south of Nantucket where “an aggregation of right whales” was seen on Monday. Federal fisheries regulators are asking mariners to either go slow or find a route around an area south of Nantucket where groups of right whales have recently been spotted as the endangered mammals migrate. ['right', 'right'] ['endangered']\n",
      "The 50,000 home health aides who work for independent agencies, on the other hand, have less oversight, lower pay, and less political power to demand protective equipment and hazard pay, she said. Four Black workers grace 13 billboards bearing the messages: “Black homecare workers are leading the fight against COVID — and racism” and “Homecare workers are fighting to be seen and heard because our lives matter. ”The goal is to prod elected officials in Massachusetts to invest in home care and to better regulate nonunion home-care agencies, said Dana Alas, organizing director for 1199SEIU United Healthcare Workers East, which is part of the Service Employees International Union and represents 50,000 personal care attendants whose program is overseen and paid for by the state. ['protective', 'grace', 'care', 'better', 'care', 'united', 'care'] ['oversight', 'hazard', 'fight', 'against', 'racism', 'fighting', 'alas']\n",
      "The National Oceanic and Atmospheric Administration said it established a “dynamic management area\" south of Nantucket where “an aggregation of right whales\" was seen on Monday. Federal fisheries regulators are asking mariners to either go slow or find a route around an area south of Nantucket where groups of right whales have recently been spotted as the endangered mammals migrate. ['right', 'right'] ['endangered']\n",
      "The 50,000 home health aides who work for independent agencies, on the other hand, have less oversight, lower pay, and less political power to demand protective equipment and hazard pay, she said. Four Black workers grace 13 billboards bearing the messages: “Black homecare workers are leading the fight against COVID — and racism\" and “Homecare workers are fighting to be seen and heard because our lives matter. \"The goal is to prod elected officials in Massachusetts to invest in home care and to better regulate nonunion home care agencies, said Dana Alas, organizing director for 1199SEIU United Healthcare Workers East, which is part of the Service Employees International Union and represents 50,000 personal care attendants whose program is overseen and paid for by the state. ['protective', 'grace', 'care', 'better', 'care', 'united', 'care'] ['oversight', 'hazard', 'fight', 'against', 'racism', 'fighting', 'alas']\n",
      "The former employee shared these concerns with the facility's executive director, the letter said, but “the concerns were not addressed. Its website says its offers concierge services, a full service salon, and a dining room with solarium. Landmark officials did not return calls from the Globe. The locks, which had been installed on several residents' doors, were supposed to protect residents from coronavirus, families were told, and inspectors said they were removed at some point in July. State elder affairs officials said that the facility's failure to comply with state regulations presents “a threat to the health, safety or welfare of its residents. But locks, considered “restraints” under state regulations, are forbidden, officials said, and raised concerns that a resident could have an emergency while locked inside. The phone rang and rang but no one picked up. \" Regulators visited Landmark at Longwood after receiving a complaint from a former employee, who cited a litany of alleged abuses, including the locked doors, medication errors, missing drugs, missing resident belongings, and verbal abuse of residents. ”It also ordered immediate corrective action -- a nurse must evaluate the skills of everyone providing personal care or dispensing of medication '”including assurance that each is capable of demonstrating appropriate infection control technique,” and the facility must a plan to screen all visitors for COVID.Landmark at Longwood has reported eight positive cases of COVID-19 -- all before June 17. ”Based on those findings, the facility may not accept new residents until state officials determine the facility is “in full compliance...with all applicable laws and regulations. ['protect', 'comply', 'safety', 'corrective', 'providing', 'care', 'assurance', 'capable', 'positive', 'determine', 'compliance'] ['failure', 'threat', 'forbidden', 'emergency', 'complaint', 'alleged', 'abuses', 'errors', 'abuse', 'infection', 'accept (with negation)']\n",
      "It's a strange way for a country to run a drug regulatory system,” he said, “where the average doctor and average citizen has to turn on CNN to find out what the truth is.” And even if the Food and Drug Administration does everything right, many people may reject the vaccine anyway if they have lost trust in the agency. The FDA already may have created a “damned-if-you-do, damned-if-you-don't” situation, said Dr. Jerry Avorn, codirector of the Program on Regulation, Therapeutics, and Law at Harvard Medical School. “ But providing objective answers to scientific questions used to be the FDA's role. “ If you end up with a good vaccine but people mistrust it,” Avorn said, “then you've won the first battle but you're losing the war. ['truth', 'right', 'trust', 'created', 'therapeutics', 'providing', 'good', 'won'] ['strange', 'reject', 'lost', 'damned', 'damned', 'mistrust', 'battle', 'losing', 'war']\n",
      "If you end up with a good vaccine but people mistrust it,\" Avorn said, “then you've won the first battle but you're losing the war.\" The FDA already may have created a “damned-if-you-do, damned-if-you-don't\" situation, said Dr. Jerry Avorn, codirector of the Program on Regulation, Therapeutics, and Law at Harvard Medical School. “ Felice J. Freyer can be reached at felice.freyer@globe.com. And even if the Food and Drug Administration does everything right, many people may reject the vaccine anyway if they have lost trust in the agency. But providing objective answers to scientific questions used to be the FDA's role. “ It's a strange way for a country to run a drug regulatory system,\" he said, “where the average doctor and average citizen has to turn on CNN to find out what the truth is.\" ['good', 'won', 'created', 'therapeutics', 'right', 'trust', 'providing', 'truth'] ['mistrust', 'battle', 'losing', 'war', 'damned', 'damned', 'reject', 'lost', 'strange']\n",
      "If you end up with a good vaccine but people mistrust it,\" Avorn said, “then you've won the first battle but you're losing the war. The FDA already may have created a “damned-if-you-do, damned-if-you-don't\" situation, said Dr. Jerry Avorn, codirector of the Program on Regulation, Therapeutics, and Law at Harvard Medical School. “ Felice J. Freyer can be reached at felice.freyer@globe.com. And even if the Food and Drug Administration does everything right, many people may reject the vaccine anyway if they have lost trust in the agency. But providing objective answers to scientific questions used to be the FDA's role. “ It's a strange way for a country to run a drug regulatory system,\" he said, “where the average doctor and average citizen has to turn on CNN to find out what the truth is.\" ['good', 'won', 'created', 'therapeutics', 'right', 'trust', 'providing', 'truth'] ['mistrust', 'battle', 'losing', 'war', 'damned', 'damned', 'reject', 'lost', 'strange']\n",
      "The former employee shared these concerns with the facility's executive director, the letter said, but “the concerns were not addressed. \"Based on those findings, the facility may not accept new residents until state officials determine the facility is “in full compliance . Its website says its offers concierge services, a full service salon, and a dining room with solarium. \"It also ordered immediate corrective action -- a nurse must evaluate the skills of everyone providing personal care or dispensing of medication \"'including assurance that each is capable of demonstrating appropriate infection control technique,\" and the facility must a plan to screen all visitors for COVID.Landmark at Longwood has reported cases of COVID-19 to the state, but not the exact number, according to the elder affairs website. Landmark officials did not return calls from the Globe. \"The locks, which had been installed on several residents' doors, were supposed to protect residents from coronavirus, families were told, and inspectors said they were removed at some point in July. with all applicable laws and regulations. State elder affairs officials said that the facility's failure to comply with state regulations presents “a threat to the health, safety or welfare of its residents. The phone rang and rang but no one picked up. \" Regulators visited Landmark at Longwood after receiving a complaint from a former employee, who cited a litany of alleged abuses, including the locked doors, medication errors, missing drugs, missing resident belongings, and verbal abuse of residents. . But locks, considered “restraints\" under state regulations, are forbidden, officials said, and raised concerns that a resident could have an emergency while locked inside. ['determine', 'compliance', 'corrective', 'providing', 'care', 'assurance', 'capable', 'protect', 'comply', 'safety'] ['accept (with negation)', 'infection', 'failure', 'threat', 'complaint', 'alleged', 'abuses', 'errors', 'abuse', 'forbidden', 'emergency']\n",
      "The recommendations were laid out in an open letter organized by the Biotechnology Innovation Organization and published Thursday. Levin and other biotech industry leaders also urged federal regulators to reassure the American public that any approval of an eventual COVID-19 vaccine or therapeutic will be motivated by science, not politics. \"“It's at the end when the result is there that one's looking for a different quality of data,\" Levin added. \"In particular, they say the Food and Drug Administration must “maintain its historic independence as the gold-standard international regulatory body, free from external influence. “Political considerations should be put aside by Republicans and Democrats alike,\" the CEOs wrote. “ \"The FDA has openly struggled to retain its independence amid growing pressure from the White House to fast-track coronavirus vaccines and treatments prior to the Nov. 3 election. Among their demands: that biotech companies don't simply release clinical trial data in press releases, and that federal regulators make it clear to the public that any vaccines or treatments will be approved strictly based on science. WASHINGTON — A group of prominent biotech CEOs are calling on their peers and the federal government to hold themselves to the highest standards when it comes to developing and reviewing COVID-19 treatments. Our nation's leaders should reassure the public that politics will not influence the development and approval of new medicines. ['open', 'innovation', 'reassure', 'approval', 'therapeutic', 'quality', 'gold', 'free', 'considerations', 'openly', 'approved', 'prominent', 'reassure', 'approval'] ['struggled', 'strictly']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(df['RegSentsExpand'][i],df['LSDposWords'][i],df['LSDnegWords'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ID','LSDposCount','LSDnegCount','LSDposWords','LSDnegWords']].to_csv('/home/ec2-user/SageMaker/New Uncertainty/Update Data/LSDsentiments_Update.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py",
   "language": "python",
   "name": "my_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
